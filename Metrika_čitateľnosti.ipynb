{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Metrika čitateľnosti\n",
        "Jakub Marták"
      ],
      "metadata": {
        "id": "klaV6CmZ-ZTq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inštalácia a import knižníc"
      ],
      "metadata": {
        "id": "cLnMSQbF-ktY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "629b93ee4fd54b7c88a1c5a096ca058a",
            "be6b9d6cf85744848068d2de2e228252",
            "e79edc15169f439dad1461963893d9e6",
            "c82d0035720c4fa5931a91fe8859c250",
            "b1fb7e9daf5f4e5d8744c4c5780a65f0",
            "e357b03f5e1844c3a48f6741ea7a013c",
            "2cc22a36040345d2a714fd3bb4899d0b",
            "fe07d95b5ae744e19e78a003c5a2a776",
            "10bab2d7e3b14aa0aab5e00faff4e66f",
            "64bf98aa73b14b60933dd7d7e6d9806c",
            "8df89b2fd2724f619a2508296bce35bf",
            "70240e545d3f419cb3aa317c399057cc",
            "4ec36093f0a145e0b1c2f969f3e082e8",
            "67a4e570553d46139e1b07ce74a2a7fd",
            "f3baf206428b495fbd377595003ea9cf",
            "242badbc4089499eb0cb01b85645bb4d",
            "8ffae1082bb9402787a624ca73342a02",
            "4b95911a7ded4e62b3fa20212175befe",
            "5a3c914f047747c8a25a28a5cbf42656",
            "9f045f5a6e8c49afb23d58d3a82f2d28",
            "ef347bacb56d4a94a1be66ef65677f7c",
            "82ce8ed476c140739dbcdeac8cc30b82",
            "48b47c0b044d4d1f8caf6e954203b903",
            "586664558c84416a9c4a29a484161ba7",
            "24292664d0174fb287b98898222c68eb",
            "699b2d71f8e8484b8438770a1f75719e",
            "c726c373b3ae480d8f1785702934b79a",
            "880673d6af50434da5bc3474f6d92f1b",
            "9a3f40c87a5742f7b3dfb6558a537a38",
            "89df0705e56445dcbd718a6e375dad6d",
            "301b833bae6e4e64993292e25c797dc7",
            "55b4d7c56f5b46cb9032b53a765e837e",
            "dc05f20ad15f451fa8fecef30fd4c7ca"
          ]
        },
        "id": "Kz39-P0qC23r",
        "outputId": "c13345ee-10ae-47cd-f47b-8d3c20d97399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting py-readability-metrics\n",
            "  Downloading py_readability_metrics-1.4.5-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from py-readability-metrics) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->py-readability-metrics) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->py-readability-metrics) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->py-readability-metrics) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->py-readability-metrics) (4.66.2)\n",
            "Installing collected packages: py-readability-metrics\n",
            "Successfully installed py-readability-metrics-1.4.5\n",
            "Collecting textstat\n",
            "  Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m881.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.14.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
            "Successfully installed pyphen-0.14.0 textstat-0.7.3\n",
            "Collecting textdescriptives\n",
            "  Downloading textdescriptives-2.8.0-py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.4/254.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy[lookups]>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from textdescriptives) (3.7.4)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from textdescriptives) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from textdescriptives) (2.0.3)\n",
            "Requirement already satisfied: pyphen<0.15.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from textdescriptives) (0.14.0)\n",
            "Collecting ftfy<6.1.0,>=6.0.3 (from textdescriptives)\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from textdescriptives) (2.6.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy<6.1.0,>=6.0.3->textdescriptives) (0.2.13)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->textdescriptives) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->textdescriptives) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->textdescriptives) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->textdescriptives) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->textdescriptives) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->textdescriptives) (4.11.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy[lookups]>=3.6.0->textdescriptives) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy[lookups]>=3.6.0->textdescriptives) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy[lookups]>=3.6.0->textdescriptives) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy[lookups]>=3.6.0->textdescriptives) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy[lookups]>=3.6.0->textdescriptives) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy[lookups]>=3.6.0->textdescriptives) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy[lookups]>=3.6.0->textdescriptives) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy[lookups]>=3.6.0->textdescriptives) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy[lookups]>=3.6.0->textdescriptives) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy[lookups]>=3.6.0->textdescriptives) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy[lookups]>=3.6.0->textdescriptives) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy[lookups]>=3.6.0->textdescriptives) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy[lookups]>=3.6.0->textdescriptives) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy[lookups]>=3.6.0->textdescriptives) (2.31.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy[lookups]>=3.6.0->textdescriptives) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy[lookups]>=3.6.0->textdescriptives) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy[lookups]>=3.6.0->textdescriptives) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy[lookups]>=3.6.0->textdescriptives) (3.3.0)\n",
            "Collecting spacy-lookups-data<1.1.0,>=1.0.3 (from spacy[lookups]>=3.6.0->textdescriptives)\n",
            "  Downloading spacy_lookups_data-1.0.5-py2.py3-none-any.whl (98.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->textdescriptives) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy[lookups]>=3.6.0->textdescriptives) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy[lookups]>=3.6.0->textdescriptives) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy[lookups]>=3.6.0->textdescriptives) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy[lookups]>=3.6.0->textdescriptives) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy[lookups]>=3.6.0->textdescriptives) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy[lookups]>=3.6.0->textdescriptives) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy[lookups]>=3.6.0->textdescriptives) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy[lookups]>=3.6.0->textdescriptives) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy[lookups]>=3.6.0->textdescriptives) (2.1.5)\n",
            "Building wheels for collected packages: ftfy\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41930 sha256=186818334e88213afb59303d0ce7f2a4a6be8b81ed7e6e3ddf90d7e907b592e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/8e/16/c1e4d4d65685d71085e4e27b44d6ed880b0559474c9ee4ff66\n",
            "Successfully built ftfy\n",
            "Installing collected packages: spacy-lookups-data, ftfy, textdescriptives\n",
            "Successfully installed ftfy-6.0.3 spacy-lookups-data-1.0.5 textdescriptives-2.8.0\n",
            "Collecting stanza\n",
            "  Downloading stanza-1.8.1-py3-none-any.whl (970 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m970.4/970.4 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting emoji (from stanza)\n",
            "  Downloading emoji-2.11.0-py2.py3-none-any.whl (433 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.8/433.8 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (3.20.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza) (2.31.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from stanza) (3.3)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from stanza) (0.10.2)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza) (4.66.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.3.0->stanza)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.3.0->stanza)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.3.0->stanza)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.3.0->stanza)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.3.0->stanza)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.3.0->stanza)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.3.0->stanza)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.3.0->stanza)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.3.0->stanza)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.3.0->stanza)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.3.0->stanza)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3.0->stanza)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->stanza) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, emoji, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stanza\n",
            "Successfully installed emoji-2.11.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 stanza-1.8.1\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "629b93ee4fd54b7c88a1c5a096ca058a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n",
            "WARNING:stanza:Language sk package default expects mwt, which has been added\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/stanza-sk/resolve/v1.8.0/models/tokenize/snk.pt:   0%|         …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70240e545d3f419cb3aa317c399057cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/stanza-sk/resolve/v1.8.0/models/mwt/snk.pt:   0%|          | 0.…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48b47c0b044d4d1f8caf6e954203b903"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Loading these models for language: sk (Slovak):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | snk     |\n",
            "| mwt       | snk     |\n",
            "=======================\n",
            "\n",
            "INFO:stanza:Using device: cpu\n",
            "INFO:stanza:Loading: tokenize\n",
            "INFO:stanza:Loading: mwt\n",
            "INFO:stanza:Done loading processors!\n",
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "!pip install py-readability-metrics\n",
        "!pip install textstat\n",
        "!pip install textdescriptives\n",
        "!pip install stanza\n",
        "!python -m spacy download en_core_web_sm\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import textstat\n",
        "from readability import Readability\n",
        "import textdescriptives as td\n",
        "from textdescriptives.utils import load_sms_data\n",
        "from textdescriptives.integrations.sklearn_featurizer import TextDescriptivesFeaturizer\n",
        "descriptive_stats_extractor = TextDescriptivesFeaturizer(lang=\"en\", metrics=[\"descriptive_stats\"])\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import graphviz\n",
        "from sklearn import set_config\n",
        "set_config(transform_output=\"pandas\")\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import stanza\n",
        "nlp = stanza.Pipeline(lang='sk', processors='tokenize', tokenize_no_ssplit=True)\n",
        "from nltk.corpus import reuters\n",
        "from nltk.tag import pos_tag\n",
        "from collections import Counter, defaultdict\n",
        "nltk.download('reuters')\n",
        "import random\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "import re\n",
        "import math\n",
        "import csv\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definícia funkcie na výpočet počtu slabík v slove"
      ],
      "metadata": {
        "id": "M9HqTozk_o8h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nGsO1MJl0CCY"
      },
      "outputs": [],
      "source": [
        "def syllab_count(slovo):\n",
        "  slovo = str(slovo)\n",
        "  vowels = \"aeiouyáéíóúýäôAEIOUYÁÉÍÓÚÝÄÔ\"\n",
        "  consonants = \"bcčdďfghjklĺľmnňpqrŕsštťvwxzžBCČDĎFGHJKLĹĽMNPQRŔSŠTŤVWXZŽ\"\n",
        "  exceptions = \"lĺrŕLĹRŔ\"\n",
        "  count = 0\n",
        "  for c in range(0, len(slovo)):\n",
        "    if slovo[c] in vowels:\n",
        "      if c > 0 and slovo[c] in \"aeuAEU\" and slovo[c-1] in \"iI\":\n",
        "        count = count + 0\n",
        "      else:\n",
        "        count = count + 1\n",
        "    if slovo[c] in exceptions and c > 0 and slovo[c-1] in consonants and c < len(slovo)-1 and slovo[c+1] in consonants:\n",
        "      count = count + 1\n",
        "  return count"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Načítanie a prvotné spracovanie predspracovaný textov pre potreby metrík čitateľnosti\n"
      ],
      "metadata": {
        "id": "N2ZwvFjp_tjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"text_MR.csv\", sep = \";\", decimal=\",\")\n",
        "df['syllables'] = 0\n",
        "for ind in df.index:\n",
        "  df['syllables'][ind] = syllab_count(df['word'][ind])\n",
        "df4 = pd.get_dummies(df.syllables)\n",
        "df4[\"many\"] = df4[5] + df4[6] + df4[7] + df4[8] + df4[9] + df4[10] + df4[11] + df4[12] + df4[13] + df4[14] + df4[15] + df4[16] + df4[17] + df4[18] + df4[19] + df4[20] + df4[22] + df4[25] + df4[26] + df4[31] + df4[32]\n",
        "df = df.join(df4[[1,2,3,4,\"many\"]])\n",
        "df2 = pd.get_dummies(df.pos)\n",
        "df = df.join(df2)\n",
        "df3 = df.groupby(['document'])[['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM',\n",
        "       'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X', 'syllables', 1, 2, 3, 4, \"many\"]].sum()\n",
        "df2 = df.groupby(['document', 'pos'])['word'].count()\n",
        "df3['document'] = df3.index\n",
        "first_column = df3.pop('document')\n",
        "df3.insert(0, 'document', first_column)\n",
        "df3['sum_words'] = df3['ADJ'] + df3['ADP'] + df3['ADV'] + df3['AUX'] + df3['CCONJ'] + df3['DET'] + df3['INTJ'] + df3['NOUN'] + df3['NUM'] + df3['PART'] + df3['PRON'] + df3['PROPN'] + df3['SCONJ'] + df3['VERB']\n",
        "df3['sum_words_2'] = df3['ADJ'] + df3['ADP'] + df3['ADV'] + df3['AUX'] + df3['CCONJ'] + df3['DET'] + df3['INTJ'] + df3['NOUN'] + df3['PART'] + df3['PRON'] + df3['PROPN'] + df3['SCONJ'] + df3['VERB']\n",
        "df3['sum_sent'] = 0\n",
        "for ind in df3.index:\n",
        "  df3['sum_sent'][ind] = len(sent_tokenize(open(df3['document'][ind]+\".txt\", \"r\").read()))\n",
        "arr = df.pos.unique()\n",
        "arr2 = df.document.unique()\n",
        "d = {'name': arr2}\n",
        "lst = []\n",
        "df2 = pd.DataFrame(data=d)\n",
        "df3.insert(0, \"index\", [23,10,11,13,21,24,27,14,17,26,12,15,18,16,0,5,30,19,22,25,20,1,2,6,8,28,31,3,7,29,9,32,4])\n",
        "df3.set_index(\"index\", inplace = True)\n",
        "df3 = df3.sort_values(by=['index'])"
      ],
      "metadata": {
        "id": "AOlJasTSHX0p"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Načítanie nespracovaných textov pre potreby metrík čitateľnosti z knižníc"
      ],
      "metadata": {
        "id": "FWUlNC8ADHIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "textlist = []\n",
        "textlist.append(open(\"Hupsov šlabikár Lipka pre 1. ročník ZŠ, 1. časť.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Pracovný zošit k Hupsovmu šlabikáru Lipka pre 1. ročník ZŠ.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Prvouka pre 1. ročník ZŠ.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Slovenský jazyk pre 2. ročník ZŠ.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Čítanka pre 2. ročník ZŠ.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Matematika pre 2. ročník ZŠ, 1. časť - pracovný zošit.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Prírodoveda pre 3. ročník ZŠ.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Slovenský jazyk pre 3. ročník ZŠ.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Prírodoveda pre 4. ročník ZŠ - pracovná učebnica.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Slovenský jazyk pre 4. ročník ZŠ.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Biológia pre 5. ročník ZŠ.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Biológia pre 6. ročník ZŠ a 1. ročník gymnázia s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Fyzika pre 6. ročník ZŠ a 1. ročník gymnázií s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Biológia pre 7. ročník ZŠ a 2. ročník gymnázia s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Dejepis pre 8. ročník ZŠ a 3. ročník gymnázia s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Fyzika pre 8. ročník ZŠ a 3. ročník gymnázia s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Geografia pre 8. ročník ZŠ a 3. ročník gymnázia s osemročným štúdiom-pages-2.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Dejepis pre 9. ročník ZŠ a 4. ročník gymnázia s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Fyzika pre 9. ročník ZŠ a 4. ročník gymnázia s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Matematika pre 9. ročník ZŠ a 4. ročník gymnázia s osemročným štúdiom, 1. časť.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Občianska náuka pre 9. ročník ZŠ a 4. ročník gymnázia s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Chémia pre 1. ročník gymnázia so štvorročným štúdiom a 5. ročník gymnázia s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Občianska náuka pre 1. ročník odborných učilíšť (pre žiakov s MP).txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Biológia 6 pre gymnáziá – Vznik života na Zemi a evolúcia, Biológia človeka.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Chémia pre 2. ročník gymnázia so štvorročným štúdiom a 6. ročník gymnázia s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Občianska náuka pre 2. ročník odborných učilíšť (pre žiakov s MP).txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Fyzika pre 3. ročník gymnázia a 7. ročník gymnázia s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Chémia pre 3. ročník gymnázia a 7. ročník gymnázia s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Slovenská literatúra pre 3. ročník stredných škôl a 7. ročník gymnázia s osemročným štúdiom s VJM.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Slovenský jazyk pre 3. ročník stredných škôl a 7. ročník gymnázia s osemročným štúdiom s VJM.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Matematika pre 4. ročník gymnázia a 8. ročník gymnázia s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Slovenská literatúra pre 4. ročník stredných škôl a 8. ročník gymnázií s osemročným štúdiom s VJM.txt\", \"r\").read().strip())\n",
        "textlist.append(open(\"Slovenský jazyk pre 4. ročník stredných škôl a 8. ročník gymnázií s osemročným štúdiom s VJM.txt\", \"r\").read().strip())"
      ],
      "metadata": {
        "id": "v8nr3ykk_-fa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Počítanie slabík v častiach textu pre potreby metriky SMOG"
      ],
      "metadata": {
        "id": "9UEGnpWzgouM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vetylist = []\n",
        "syllabelsstart = []\n",
        "syllabelsend = []\n",
        "syllabelsmid = []\n",
        "for i in textlist:\n",
        "  vetylist.append(sent_tokenize(i))\n",
        "for i in vetylist:\n",
        "  for j in i[:10]:\n",
        "    nltk_tokens = nltk.word_tokenize(j)\n",
        "    syl = 0\n",
        "    for k in nltk_tokens:\n",
        "      if syllab_count(k) >= 3:\n",
        "        syl = syl + 1\n",
        "  syllabelsstart.append(syl)\n",
        "  for j in i[-10:]:\n",
        "    nltk_tokens = nltk.word_tokenize(j)\n",
        "    syl = 0\n",
        "    for k in nltk_tokens:\n",
        "      if syllab_count(k) >= 3:\n",
        "        syl = syl + 1\n",
        "  syllabelsend.append(syl)\n",
        "  for j in i[round(len(i)/2)-5:round(len(i)/2)+5]:\n",
        "    nltk_tokens = nltk.word_tokenize(j)\n",
        "    syl = 0\n",
        "    for k in nltk_tokens:\n",
        "      if syllab_count(k) >= 3:\n",
        "        syl = syl + 1\n",
        "  syllabelsmid.append(syl)\n",
        "df3[\"syl_start\"] = syllabelsstart\n",
        "df3[\"syl_end\"] = syllabelsend\n",
        "df3[\"syl_mid\"] = syllabelsmid"
      ],
      "metadata": {
        "id": "wITNHckMDSUl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Počítanie slabík a iných charakteristík textu pre potreby metriky Gunning-Fog."
      ],
      "metadata": {
        "id": "2Stplcx6g1g7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vetylist = []\n",
        "gun_sent = []\n",
        "gun_word = []\n",
        "gun_hard_word = []\n",
        "for i in textlist:\n",
        "  vetylist.append(sent_tokenize(i))\n",
        "for i in vetylist:\n",
        "  pocviet = 0\n",
        "  pocslov = 0\n",
        "  poctazslov = 0\n",
        "  for j in i:\n",
        "    pocviet = pocviet + 1\n",
        "    nltk_tokens = nltk.word_tokenize(j)\n",
        "    for k in nltk_tokens:\n",
        "      if syllab_count(k) > 0:\n",
        "        pocslov = pocslov + 1\n",
        "        if \".\" not in k and \"-\" not in k and \"…\" not in k and \"'\" not in k:\n",
        "          sl_druh = \"\"\n",
        "          try:\n",
        "            sl_druh = df.loc[df['word'] == k][\"pos\"].loc[df.loc[df['word'] == k].index[0]]\n",
        "            lema = df.loc[df['word'] == k][\"lemma\"].loc[df.loc[df['word'] == k].index[0]]\n",
        "            if syllab_count(lema) >= 3 and sl_druh != \"NOUN\":\n",
        "              poctazslov = poctazslov + 1\n",
        "          except:\n",
        "            #print(k)\n",
        "            if syllab_count(k) >= 3 and sl_druh != \"NOUN\":\n",
        "              poctazslov = poctazslov + 1\n",
        "    if pocslov >= 100:\n",
        "      gun_sent.append(pocviet)\n",
        "      gun_word.append(pocslov)\n",
        "      gun_hard_word.append(poctazslov)\n",
        "      pocviet = 0\n",
        "      pocslov = 0\n",
        "      poctazslov = 0\n",
        "      break\n",
        "df3[\"gun_sent\"] = gun_sent\n",
        "df3[\"gun_word\"] = gun_word\n",
        "df3[\"gun_hard_word\"] = gun_hard_word"
      ],
      "metadata": {
        "id": "y85b_uXhseIa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Počítanie slabík a iných charakteristík textu pre potreby metriky Linsear-Write"
      ],
      "metadata": {
        "id": "tsllgxd-osxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "charlist = []\n",
        "for i in textlist:\n",
        "  charlist.append(len(i))\n",
        "df3[\"charlist\"] = charlist\n",
        "vetylist = []\n",
        "lin_syl = []\n",
        "for i in textlist:\n",
        "  vetylist.append(sent_tokenize(i))\n",
        "for i in vetylist:\n",
        "  wordlist = []\n",
        "  pocslov = 0\n",
        "  for j in i:\n",
        "    pocviet = pocviet + 1\n",
        "    nltk_tokens = nltk.word_tokenize(j)\n",
        "    for k in nltk_tokens:\n",
        "      if syllab_count(k) > 0:\n",
        "        pocslov = pocslov + 1\n",
        "        wordlist.append(k)\n",
        "    if pocslov >= 100:\n",
        "      pocslov = 0\n",
        "      break\n",
        "  wordlist = wordlist[:100]\n",
        "  syl = 0\n",
        "  for l in wordlist:\n",
        "    if syllab_count(l) >= 3:\n",
        "      syl = syl + 3\n",
        "    else:\n",
        "      syl = syl + 1\n",
        "  lin_syl.append(syl)\n",
        "df3[\"lin_syl\"] = lin_syl"
      ],
      "metadata": {
        "id": "RIyF86EuhFC7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tvorba zoznamu najpoužívanejších lem pre potreby metrík Dale-Chall a Spache"
      ],
      "metadata": {
        "id": "KbyveaC69pae"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kDKiDfq0F5a_"
      },
      "outputs": [],
      "source": [
        "kw = pd.read_csv(\"prim-10.0-public-all-lemma_frequency.txt\", sep = \" \", quoting=csv.QUOTE_NONE)\n",
        "kw = kw.loc[:9999]\n",
        "keywords = kw[\"Form\"].tolist()\n",
        "keywords = list(dict.fromkeys(keywords))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Výpočet priemernej dĺžky slova v slovenčine (v slabikách)."
      ],
      "metadata": {
        "id": "ipZ4xhlY-PYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kw2 = pd.read_csv(\"prim-10.0-public-all-word_frequency.txt\", sep = \" \", quoting=csv.QUOTE_NONE)\n",
        "keywords2 = kw2[\"Form\"].tolist()\n",
        "count2 = kw2[\"Count\"].tolist()\n",
        "supersum = 0\n",
        "j = 0\n",
        "k = 0\n",
        "for i in keywords2:\n",
        "  supersum = supersum + syllab_count(i) * count2[j]\n",
        "  j = j + 1\n",
        "  if syllab_count(i) > 0:\n",
        "    k = k + count2[j]\n",
        "print(supersum/k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMf1BlbiSgYe",
        "outputId": "b022b4c8-1c0c-4c52-dc72-82d04adf8026"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4135384846342385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Počítanie ťažkých a unikátnych slov pre potreby metrík Dale-Chall a Mistríkovej metriky."
      ],
      "metadata": {
        "id": "giGI_UktBz84"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qNkUUSeUBtAC"
      },
      "outputs": [],
      "source": [
        "vetylist = []\n",
        "hard_words = []\n",
        "unique_words = []\n",
        "for i in textlist:\n",
        "  vetylist.append(sent_tokenize(i))\n",
        "for i in vetylist:\n",
        "  pocunikslov = 0\n",
        "  poctazslov = 0\n",
        "  for j in i:\n",
        "    nltk_tokens = nltk.word_tokenize(j)\n",
        "    pocunikslov = pocunikslov + len(Counter(nltk_tokens).keys())\n",
        "    for k in nltk_tokens:\n",
        "      if syllab_count(k) > 0:\n",
        "        if k not in keywords:\n",
        "          poctazslov = poctazslov + 1\n",
        "  hard_words.append(poctazslov)\n",
        "  unique_words.append(pocunikslov)\n",
        "df3[\"hard_words\"] = hard_words\n",
        "df3[\"unique_words\"] = unique_words\n",
        "df3.to_csv('tab1.csv', sep=';', encoding='utf-16', index=False)\n",
        "df.to_csv('text_MR_2.csv', sep=';', encoding='utf-16', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzlcG5z_LS8o"
      },
      "source": [
        "### Výpočet výsledkov metrík z knižnice **TextDescriptives:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dc5vFTMcoic2"
      },
      "outputs": [],
      "source": [
        "metricslist = []\n",
        "for i in textlist:\n",
        "  metricslist.append(td.extract_metrics(text=i, lang=\"en\", metrics=['readability']))\n",
        "dfTD = pd.concat(metricslist)\n",
        "dfTD.insert(0, \"name\", [\"metrics1SJ\",\"metrics1SJL\",\"metrics1PR\",\"metrics2SJ\",\"metrics2SJL\",\"metrics2MAT\",\"metrics3PR\",\"metrics3SJ\",\"metrics4PR\",\"metrics4SJ\",\"metrics5PR\",\"metrics6PR\",\"metrics6FYZ\",\"metrics7PR\",\"metrics8DEJ\",\"metrics8FYZ\",\"metrics8GEO\",\"metrics9DEJ\",\"metrics9FYZ\",\"metrics9MAT\",\"metrics9OBN\",\"metrics10CHE\",\"metrics10OBN\",\"metrics11PR\",\"metrics11CHE\",\"metrics11OBN\",\"metrics12FYZ\",\"metrics12CHE\",\"metrics12SJL\",\"metrics12SJ\",\"metrics13MAT\",\"metrics13SJL\",\"metrics13SJ\"])\n",
        "dfTD.insert(1, \"document\", [\"Hupsov šlabikár Lipka pre 1. ročník ZŠ, 1. časť\",\"Pracovný zošit k Hupsovmu šlabikáru Lipka pre 1. ročník ZŠ\",\"Prvouka pre 1. ročník ZŠ\",\"Slovenský jazyk pre 2. ročník ZŠ\",\"Čítanka pre 2. ročník ZŠ\",\"Matematika pre 2. ročník ZŠ, 1. časť - pracovný zošit\",\"Prírodoveda pre 3. ročník ZŠ\",\"Slovenský jazyk pre 3. ročník ZŠ\",\"Prírodoveda pre 4. ročník ZŠ - pracovná učebnica\",\"Slovenský jazyk pre 4. ročník ZŠ\",\"Biológia pre 5. ročník ZŠ\",\"Biológia pre 6. ročník ZŠ a 1. ročník gymnázia s osemročným štúdiom\",\"Fyzika pre 6. ročník ZŠ a 1. ročník gymnázií s osemročným štúdiom\",\"Biológia pre 7. ročník ZŠ a 2. ročník gymnázia s osemročným štúdiom\",\"Dejepis pre 8. ročník ZŠ a 3. ročník gymnázia s osemročným štúdiom\",\"Fyzika pre 8. ročník ZŠ a 3. ročník gymnázia s osemročným štúdiom\",\"Geografia pre 8. ročník ZŠ a 3. ročník gymnázia s osemročným štúdiom-pages-2\",\"Dejepis pre 9. ročník ZŠ a 4. ročník gymnázia s osemročným štúdiom\",\"Fyzika pre 9. ročník ZŠ a 4. ročník gymnázia s osemročným štúdiom\",\"Matematika pre 9. ročník ZŠ a 4. ročník gymnázia s osemročným štúdiom, 1. časť\",\"Občianska náuka pre 9. ročník ZŠ a 4. ročník gymnázia s osemročným štúdiom\",\"Chémia pre 1. ročník gymnázia so štvorročným štúdiom a 5. ročník gymnázia s osemročným štúdiom\",\"Občianska náuka pre 1. ročník odborných učilíšť (pre žiakov s MP)\",\"Biológia 6 pre gymnáziá – Vznik života na Zemi a evolúcia, Biológia človeka\",\"Chémia pre 2. ročník gymnázia so štvorročným štúdiom a 6. ročník gymnázia s osemročným štúdiom\",\"Občianska náuka pre 2. ročník odborných učilíšť (pre žiakov s MP)\",\"Fyzika pre 3. ročník gymnázia a 7. ročník gymnázia s osemročným štúdiom\",\"Chémia pre 3. ročník gymnázia a 7. ročník gymnázia s osemročným štúdiom\",\"Slovenská literatúra pre 3. ročník stredných škôl a 7. ročník gymnázia s osemročným štúdiom s VJM\",\"Slovenský jazyk pre 3. ročník stredných škôl a 7. ročník gymnázia s osemročným štúdiom s VJM\",\"Matematika pre 4. ročník gymnázia a 8. ročník gymnázia s osemročným štúdiom\",\"Slovenská literatúra pre 4. ročník stredných škôl a 8. ročník gymnázií s osemročným štúdiom s VJM\",\"Slovenský jazyk pre 4. ročník stredných škôl a 8. ročník gymnázií s osemročným štúdiom s VJM\"])\n",
        "dfTD.insert(2, \"grade\", [1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3])\n",
        "dfTD.insert(3, \"year\", [1,1,1,2,2,2,3,3,4,4,5,6,6,7,8,8,8,9,9,9,9,10,10,11,11,11,12,12,12,12,13,13,13])\n",
        "dfTD.insert(4, \"subject\", [\"SJ\",\"SJL\",\"PR\",\"SJ\",\"SJL\",\"MAT\",\"PR\",\"SJ\",\"PR\",\"SJ\",\"PR\",\"PR\",\"FYZ\",\"PR\",\"DEJ\",\"FYZ\",\"GEO\",\"DEJ\",\"FYZ\",\"MAT\",\"OBN\",\"CHE\",\"OBN\",\"PR\",\"CHE\",\"OBN\",\"FYZ\",\"CHE\",\"SJL\",\"SJ\",\"MAT\",\"SJL\",\"SJ\"])\n",
        "dfTD.reset_index(inplace = True)\n",
        "dfTD = dfTD.drop([\"index\",\"text\"], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeteKMYsN-xC"
      },
      "source": [
        "Pre sk a cs nie sú dostupné metriky. Pracujeme s en."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPUtipCHbqOg"
      },
      "source": [
        "### Výpočet výsledkov metrík z knižnice **Py-Readability-Metrics:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Swom_xzcwHjW"
      },
      "outputs": [],
      "source": [
        "Readabilitylist = []\n",
        "for i in textlist:\n",
        "  Readabilitylist.append(Readability(i))\n",
        "fklist = []\n",
        "fklist_score = []\n",
        "fklist_grade_level = []\n",
        "flist = []\n",
        "flist_score = []\n",
        "flist_ease = []\n",
        "flist_grade_level = []\n",
        "dclist = []\n",
        "dclist_score = []\n",
        "dclist_grade_level = []\n",
        "arilist = []\n",
        "arilist_score = []\n",
        "arilist_grade_level = []\n",
        "arilist_ages = []\n",
        "cllist = []\n",
        "cllist_score = []\n",
        "cllist_grade_level = []\n",
        "gflist = []\n",
        "gflist_score = []\n",
        "gflist_grade_level = []\n",
        "smoglist = []\n",
        "smoglist_score = []\n",
        "smoglist_grade_level = []\n",
        "smogalist = []\n",
        "smogalist_score = []\n",
        "smogalist_grade_level = []\n",
        "slist = []\n",
        "slist_score = []\n",
        "slist_grade_level = []\n",
        "lwlist = []\n",
        "lwlist_score = []\n",
        "lwlist_grade_level = []\n",
        "for i in Readabilitylist:\n",
        "  fklist.append(i.flesch_kincaid())\n",
        "  flist.append(i.flesch())\n",
        "  dclist.append(i.dale_chall())\n",
        "  arilist.append(i.ari())\n",
        "  cllist.append(i.coleman_liau())\n",
        "  gflist.append(i.gunning_fog())\n",
        "  smoglist.append(i.smog())\n",
        "  smogalist.append(i.smog(all_sentences=True))\n",
        "  slist.append(i.spache())\n",
        "  lwlist.append(i.linsear_write())\n",
        "for i in fklist:\n",
        "  fklist_score.append(i.score)\n",
        "  fklist_grade_level.append(i.grade_level)\n",
        "dfTD.insert(len(dfTD.columns),\"R_flesch_kincaid_score\", fklist_score, True)\n",
        "dfTD.insert(len(dfTD.columns),\"R_flesch_kincaid_grade_level\", fklist_grade_level, True)\n",
        "for i in flist:\n",
        "  flist_score.append(i.score)\n",
        "  flist_ease.append(i.ease)\n",
        "  flist_grade_level.append(i.grade_levels)\n",
        "dfTD.insert(len(dfTD.columns),\"R_flesch_score\", flist_score, True)\n",
        "dfTD.insert(len(dfTD.columns),\"R_flesch_ease\", flist_ease, True)\n",
        "dfTD.insert(len(dfTD.columns),\"R_flesch_grade_levels\", flist_grade_level, True)\n",
        "for i in dclist:\n",
        "  dclist_score.append(i.score)\n",
        "  dclist_grade_level.append(i.grade_levels)\n",
        "dfTD.insert(len(dfTD.columns),\"R_dale_chall_score\", dclist_score, True)\n",
        "dfTD.insert(len(dfTD.columns),\"R_dale_chall_grade_levels\", dclist_grade_level, True)\n",
        "for i in arilist:\n",
        "  arilist_score.append(i.score)\n",
        "  arilist_ages.append(i.ages)\n",
        "  arilist_grade_level.append(i.grade_levels)\n",
        "dfTD.insert(len(dfTD.columns),\"R_ari_score\", arilist_score, True)\n",
        "dfTD.insert(len(dfTD.columns),\"R_ari_grade_levels\", arilist_grade_level, True)\n",
        "dfTD.insert(len(dfTD.columns),\"R_ari_ages\", arilist_ages, True)\n",
        "for i in cllist:\n",
        "  cllist_score.append(i.score)\n",
        "  cllist_grade_level.append(i.grade_level)\n",
        "dfTD.insert(len(dfTD.columns),\"R_coleman_liau_score\", cllist_score, True)\n",
        "dfTD.insert(len(dfTD.columns),\"R_coleman_liau_grade_level\", cllist_grade_level, True)\n",
        "for i in gflist:\n",
        "  gflist_score.append(i.score)\n",
        "  gflist_grade_level.append(i.grade_level)\n",
        "dfTD.insert(len(dfTD.columns),\"R_gunning_fog_score\", gflist_score, True)\n",
        "dfTD.insert(len(dfTD.columns),\"R_gunning_fog_grade_level\", gflist_grade_level, True)\n",
        "for i in smoglist:\n",
        "  smoglist_score.append(i.score)\n",
        "  smoglist_grade_level.append(i.grade_level)\n",
        "dfTD.insert(len(dfTD.columns),\"R_smog_score\", smoglist_score, True)\n",
        "dfTD.insert(len(dfTD.columns),\"R_smog_grade_level\", smoglist_grade_level, True)\n",
        "for i in smogalist:\n",
        "  smogalist_score.append(i.score)\n",
        "  smogalist_grade_level.append(i.grade_level)\n",
        "dfTD.insert(len(dfTD.columns),\"R_smog_all_sentences_score\", smogalist_score, True)\n",
        "dfTD.insert(len(dfTD.columns),\"R_smog_all_sentences_grade_level\", smogalist_grade_level, True)\n",
        "for i in slist:\n",
        "  slist_score.append(i.score)\n",
        "  slist_grade_level.append(i.grade_level)\n",
        "dfTD.insert(len(dfTD.columns),\"R_spache_score\", slist_score, True)\n",
        "dfTD.insert(len(dfTD.columns),\"R_spache_grade_level\", slist_grade_level, True)\n",
        "for i in lwlist:\n",
        "  lwlist_score.append(i.score)\n",
        "  lwlist_grade_level.append(i.grade_level)\n",
        "dfTD.insert(len(dfTD.columns),\"R_linsear_write_score\", lwlist_score, True)\n",
        "dfTD.insert(len(dfTD.columns),\"R_linsear_write_grade_level\", lwlist_grade_level, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFKdc7nEqJZO"
      },
      "source": [
        "### Výpočet výsledkov metrík z knižnice **TextStat:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "C6qVehunbmtx"
      },
      "outputs": [],
      "source": [
        "tfllist = []\n",
        "tfkglist = []\n",
        "tgflist = []\n",
        "tsmoglist = []\n",
        "tarilist = []\n",
        "tcllist = []\n",
        "tdclist = []\n",
        "tstdlist = []\n",
        "tlwlist = []\n",
        "tslist = []\n",
        "teflawlist = []\n",
        "trtlist = []\n",
        "tsyllist = []\n",
        "tlexlist = []\n",
        "tsentlist = []\n",
        "tcharlist = []\n",
        "tletlist = []\n",
        "tpolylist = []\n",
        "tmonolist = []\n",
        "tdifflist = []\n",
        "for i in textlist:\n",
        "  tfllist.append(textstat.flesch_reading_ease(i))\n",
        "  tfkglist.append(textstat.flesch_kincaid_grade(i))\n",
        "  tgflist.append(textstat.gunning_fog(i))\n",
        "  tsmoglist.append(textstat.smog_index(i))\n",
        "  tarilist.append(textstat.automated_readability_index(i))\n",
        "  tcllist.append(textstat.coleman_liau_index(i))\n",
        "  tlwlist.append(textstat.linsear_write_formula(i))\n",
        "  tdclist.append(textstat.dale_chall_readability_score(i))\n",
        "  tstdlist.append(textstat.text_standard(i, float_output=False))\n",
        "  tslist.append(textstat.spache_readability(i))\n",
        "  teflawlist.append(textstat.mcalpine_eflaw(i))\n",
        "  trtlist.append(textstat.reading_time(i, ms_per_char=14.69))\n",
        "  tsyllist.append(textstat.syllable_count(i))\n",
        "  tlexlist.append(textstat.lexicon_count(i, removepunct=True))\n",
        "  tsentlist.append(textstat.sentence_count(i))\n",
        "  tcharlist.append(textstat.char_count(i, ignore_spaces=True))\n",
        "  tletlist.append(textstat.letter_count(i, ignore_spaces=True))\n",
        "  tpolylist.append(textstat.polysyllabcount(i))\n",
        "  tmonolist.append(textstat.monosyllabcount(i))\n",
        "  tdifflist.append(textstat.difficult_words(i))\n",
        "dfTD.insert(len(dfTD.columns),\"T_flesch_reading_ease\", tfllist, True)\n",
        "dfTD.insert(len(dfTD.columns),\"T_flesch_kincaid_grade\", tfkglist, True)\n",
        "dfTD.insert(len(dfTD.columns),\"T_gunning_fog\", tgflist, True)\n",
        "dfTD.insert(len(dfTD.columns),\"T_smog_index\", tsmoglist, True)\n",
        "dfTD.insert(len(dfTD.columns),\"T_automated_readability_index\", tarilist, True)\n",
        "dfTD.insert(len(dfTD.columns),\"T_coleman_liau_index\", tcllist, True)\n",
        "dfTD.insert(len(dfTD.columns),\"T_linsear_write_formula\", tlwlist, True)\n",
        "dfTD.insert(len(dfTD.columns),\"T_dale_chall_readability_score\", tdclist, True)\n",
        "dfTD.insert(len(dfTD.columns),\"T_text_standard\", tstdlist, True)\n",
        "dfTD.insert(len(dfTD.columns),\"T_spache_readability\", tslist, True)\n",
        "dfTD.insert(len(dfTD.columns),\"T_mcalpine_eflaw\", teflawlist, True)\n",
        "dfTD.insert(len(dfTD.columns),\"T_reading_time\", trtlist, True)\n",
        "dfTD.insert(len(dfTD.columns),\"T_syllable_count\", tsyllist, True)\n",
        "dfTD.insert(len(dfTD.columns),\"T_lexicon_count\", tlexlist, True)\n",
        "dfTD.insert(len(dfTD.columns),\"T_sentence_count\", tsentlist, True)\n",
        "dfTD.insert(len(dfTD.columns),\"T_char_count\", tcharlist, True)\n",
        "dfTD.insert(len(dfTD.columns),\"T_letter_count\", tletlist, True)\n",
        "dfTD.insert(len(dfTD.columns),\"T_polysyllabcount\", tpolylist, True)\n",
        "dfTD.insert(len(dfTD.columns),\"T_monosyllabcount\", tmonolist, True)\n",
        "dfTD.insert(len(dfTD.columns),\"T_difficult_words\", tdifflist, True)\n",
        "dfTD.to_csv('tab2.csv', sep=';', encoding='utf-16', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQro1Hcxh6nQ"
      },
      "source": [
        "## Medzisúčty pre naše vzorce:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vjsBBVylxQt_"
      },
      "outputs": [],
      "source": [
        "dfcomp = dfTD[['name', \"document\", 'year', 'grade', 'subject', 'token_length_mean', 'token_length_median', 'token_length_std', 'sentence_length_mean', 'sentence_length_median', 'sentence_length_std', 'syllables_per_token_mean', 'syllables_per_token_median', 'syllables_per_token_std', 'n_tokens', 'T_lexicon_count', 'n_unique_tokens', 'proportion_unique_tokens', 'n_characters', 'T_char_count', 'T_letter_count', 'n_sentences', 'T_sentence_count', 'T_reading_time', 'T_syllable_count', 'T_polysyllabcount', 'T_monosyllabcount', 'T_difficult_words']]\n",
        "dfcomp.insert(15, \"sum_words\", df3[\"sum_words\"])\n",
        "dfcomp.insert(16, \"sum_words_2\", df3[\"sum_words_2\"])\n",
        "dfcomp.insert(22, \"charlist\", df3[\"charlist\"])\n",
        "dfcomp.insert(23, \"sum_sent\", df3[\"sum_sent\"])\n",
        "dfcomp.insert(27, \"syllables\", df3[\"syllables\"])\n",
        "dfcomp.insert(29, \"multi syllables\", df3[2] + df3[3] + df3[4] + df3[\"many\"])\n",
        "dfcomp.insert(30, \"two syllables\", df3[2])\n",
        "dfcomp.insert(31, \"three syllables\", df3[3])\n",
        "dfcomp.insert(32, \"four syllables\", df3[4])\n",
        "dfcomp.insert(34, \"many syllables\", df3[\"many\"])\n",
        "dfcomp.insert(36, \"single syllables\", df3[1])\n",
        "dfcomp.insert(38, \"smog_syllables\", df3[\"syl_start\"]+df3[\"syl_end\"]+df3[\"syl_mid\"])\n",
        "dfcomp.insert(40, \"gun_sent\", df3[\"gun_sent\"])\n",
        "dfcomp.insert(41, \"gun_word\", df3[\"gun_word\"])\n",
        "dfcomp.insert(42, \"gun_hard_word\", df3[\"gun_hard_word\"])\n",
        "dfcomp.insert(43, \"lin_syl\", df3[\"lin_syl\"])\n",
        "dfcomp.insert(44, \"hard_words\", df3[\"hard_words\"])\n",
        "dfcomp.insert(45, \"unique_words\", df3[\"unique_words\"])\n",
        "dfcomp.insert(46, \"NUM\", df3[\"NUM\"])\n",
        "dfcomp.insert(47, \"PROPN\", df3[\"PROPN\"])\n",
        "dfcomp.insert(48, \"SCONJ\", df3[\"SCONJ\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53ffiTlFQ_pl"
      },
      "source": [
        "## Výpočet našich vlastných vzorcov:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "RNn5krmIvVEp"
      },
      "outputs": [],
      "source": [
        "dfmetr = dfTD[['name', \"document\", 'year', 'grade', 'subject', 'flesch_kincaid_grade', 'R_flesch_kincaid_grade_level', 'T_flesch_kincaid_grade', 'smog', 'R_smog_score', 'R_smog_all_sentences_score', 'T_smog_index', 'gunning_fog', 'R_gunning_fog_score', 'T_gunning_fog', 'automated_readability_index', 'R_ari_score', 'T_automated_readability_index', 'coleman_liau_index', 'R_coleman_liau_score', 'T_coleman_liau_index', 'R_spache_score', 'T_spache_readability', 'R_linsear_write_score', 'T_linsear_write_formula', 'R_dale_chall_score', 'T_dale_chall_readability_score']]\n",
        "dfmetr.insert(8, \"M_flesch_kincaid\", 0)\n",
        "dfmetr.insert(13, \"M_smog\", 0)\n",
        "dfmetr.insert(17, \"M_gunning_fog\", 0)\n",
        "dfmetr.insert(21, \"M_ari\", 0)\n",
        "dfmetr.insert(25, \"M_coleman_liau\", 0)\n",
        "dfmetr.insert(28, \"M_spache\", 0)\n",
        "dfmetr.insert(31, \"M_linsear_write\", 0)\n",
        "dfmetr.insert(34, \"M_dale_chall\", 0)\n",
        "dfmetr.insert(35, \"M_Mistrík\", 0)\n",
        "for ind in dfmetr.index:\n",
        "  dfmetr['M_flesch_kincaid'][ind] = 0.39*(dfcomp[\"sum_words\"][ind]/dfcomp[\"sum_sent\"][ind])+11.8*(dfcomp[\"syllables\"][ind]/dfcomp[\"sum_words\"][ind])-15.59\n",
        "  dfmetr['M_smog'][ind] = 3 + math.sqrt(dfcomp['smog_syllables'][ind])\n",
        "  dfmetr['M_gunning_fog'][ind] = 0.4*(dfcomp['gun_word'][ind]/dfcomp['gun_sent'][ind] + 100*(dfcomp['gun_hard_word'][ind]/dfcomp['gun_word'][ind]))\n",
        "  dfmetr['M_ari'][ind] = 0.5*(dfcomp['sum_words'][ind]/dfcomp['sum_sent'][ind]) + 4.71*(dfcomp['charlist'][ind]/dfcomp['sum_words'][ind])-21.43\n",
        "  dfmetr['M_coleman_liau'][ind] = 5.88*(dfcomp['charlist'][ind]/dfcomp['sum_words'][ind])-29.6*(dfcomp['sum_sent'][ind]/dfcomp['sum_words'][ind])-15.8\n",
        "  dfmetr['M_spache'][ind] = (0.121*dfcomp['sum_words'][ind]/dfcomp['sum_sent'][ind])+(8.2*dfcomp['hard_words'][ind]/dfcomp['sum_words'][ind])+0.659\n",
        "  if (dfcomp['lin_syl'][ind]/dfcomp['gun_sent'][ind]) > 20:\n",
        "    dfmetr['M_linsear_write'][ind] = (dfcomp['lin_syl'][ind]/dfcomp['gun_sent'][ind])/2\n",
        "  else:\n",
        "    dfmetr['M_linsear_write'][ind] = (dfcomp['lin_syl'][ind]/dfcomp['gun_sent'][ind])/2-1\n",
        "  dfmetr['M_dale_chall'][ind] = 0.1579*(dfcomp['hard_words'][ind]/dfcomp['sum_words'][ind]*100) + 0.0496*(dfcomp['sum_words'][ind]/dfcomp['sum_sent'][ind])\n",
        "  dfmetr['M_Mistrík'][ind] = 50-(((dfcomp['sum_words'][ind]/dfcomp['sum_sent'][ind])*(dfcomp[\"syllables\"][ind]/dfcomp[\"sum_words\"][ind]))/(dfcomp[\"sum_words\"][ind]/dfcomp[\"unique_words\"][ind]))\n",
        "  #*(1+(dfcomp[\"sum_words\"][ind]/(dfcomp[\"NUM\"][ind]+dfcomp[\"PROPN\"][ind])))*(1+(dfcomp[\"SCONJ\"][ind]/dfcomp[\"sum_words\"][ind])))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Výpočet našich vlastných vzorcov, kde nepovažujeme čísla za slová:"
      ],
      "metadata": {
        "id": "56_rrPj0CwGZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "b4riO-MdHgF0"
      },
      "outputs": [],
      "source": [
        "dfmetrx = dfTD[['name', \"document\", 'year', 'grade', 'subject']]\n",
        "dfmetrx.insert(5, \"M_flesch_kincaid\", 0)\n",
        "dfmetrx.insert(6, \"M_smog\", 0)\n",
        "dfmetrx.insert(7, \"M_gunning_fog\", 0)\n",
        "dfmetrx.insert(8, \"M_ari\", 0)\n",
        "dfmetrx.insert(9, \"M_coleman_liau\", 0)\n",
        "dfmetrx.insert(10, \"M_spache\", 0)\n",
        "dfmetrx.insert(11, \"M_linsear_write\", 0)\n",
        "dfmetrx.insert(12, \"M_dale_chall\", 0)\n",
        "dfmetrx.insert(13, \"M_Mistrík\", 0)\n",
        "for ind in dfmetrx.index:\n",
        "  dfmetrx['M_flesch_kincaid'][ind] = 0.39*(dfcomp[\"sum_words_2\"][ind]/dfcomp[\"sum_sent\"][ind])+11.8*(dfcomp[\"syllables\"][ind]/dfcomp[\"sum_words_2\"][ind])-15.59\n",
        "  dfmetrx['M_smog'][ind] = 3 + math.sqrt(dfcomp['smog_syllables'][ind])\n",
        "  dfmetrx['M_gunning_fog'][ind] = 0.4*(dfcomp['gun_word'][ind]/dfcomp['gun_sent'][ind] + 100*(dfcomp['gun_hard_word'][ind]/dfcomp['gun_word'][ind]))\n",
        "  dfmetrx['M_ari'][ind] = 0.5*(dfcomp['sum_words'][ind]/dfcomp['sum_sent'][ind]) + 4.71*(dfcomp['charlist'][ind]/dfcomp['sum_words'][ind])-21.43\n",
        "  dfmetrx['M_coleman_liau'][ind] = 5.88*(dfcomp['charlist'][ind]/dfcomp['sum_words'][ind])-29.6*(dfcomp['sum_sent'][ind]/dfcomp['sum_words'][ind])-15.8\n",
        "  dfmetrx['M_spache'][ind] = (0.121*dfcomp['sum_words_2'][ind]/dfcomp['sum_sent'][ind])+(8.2*dfcomp['hard_words'][ind]/dfcomp['sum_words_2'][ind])+0.659\n",
        "  if (dfcomp['lin_syl'][ind]/dfcomp['gun_sent'][ind]) > 20:\n",
        "    dfmetrx['M_linsear_write'][ind] = (dfcomp['lin_syl'][ind]/dfcomp['gun_sent'][ind])/2\n",
        "  else:\n",
        "    dfmetrx['M_linsear_write'][ind] = (dfcomp['lin_syl'][ind]/dfcomp['gun_sent'][ind])/2-1\n",
        "  dfmetrx['M_dale_chall'][ind] = 0.1579*(dfcomp['hard_words'][ind]/dfcomp['sum_words_2'][ind]*100) + 0.0496*(dfcomp['sum_words_2'][ind]/dfcomp['sum_sent'][ind])\n",
        "  dfmetrx['M_Mistrík'][ind] = 50-(((dfcomp['sum_words_2'][ind]/dfcomp['sum_sent'][ind])*(dfcomp[\"syllables\"][ind]/dfcomp[\"sum_words_2\"][ind]))/(dfcomp[\"sum_words_2\"][ind]/dfcomp[\"unique_words\"][ind]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM1xskYPVuDv"
      },
      "source": [
        "## Teraz celý postup zopakujeme po odstránení úvodov a záverov z pôvodných textov:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfx = pd.read_csv(\"text_MR34.csv\", sep = \";\", decimal=\",\")\n",
        "dfx['syllables'] = 0\n",
        "for ind in dfx.index:\n",
        "  dfx['syllables'][ind] = syllab_count(dfx['word'][ind])\n",
        "df5 = pd.get_dummies(dfx.syllables)\n",
        "df5[\"many\"] = df5[5] + df5[6] + df5[7] + df5[8] + df5[9] + df5[10] + df5[11] + df5[12] + df5[13] + df5[14] + df5[15] + df5[17] + df5[18] + df5[20] + df5[22] + df5[26] + df5[31] + df5[32]\n",
        "dfx = dfx.join(df5[[1,2,3,4,\"many\"]])\n",
        "dfx2 = pd.get_dummies(dfx.pos)\n",
        "dfx = dfx.join(dfx2)\n",
        "dfx3 = dfx.groupby(['document'])[['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM',\n",
        "       'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X', 'syllables', 1, 2, 3, 4, \"many\"]].sum()\n",
        "dfx2 = dfx.groupby(['document', 'pos'])['word'].count()\n",
        "dfx3['document'] = dfx3.index\n",
        "first_column = dfx3.pop('document')\n",
        "dfx3.insert(0, 'document', first_column)\n",
        "dfx3['sum_words'] = dfx3['ADJ'] + dfx3['ADP'] + dfx3['ADV'] + dfx3['AUX'] + dfx3['CCONJ'] + dfx3['DET'] + dfx3['INTJ'] + dfx3['NOUN'] + dfx3['NUM'] + dfx3['PART'] + dfx3['PRON'] + dfx3['PROPN'] + dfx3['SCONJ'] + dfx3['VERB']\n",
        "dfx3['sum_words_2'] = dfx3['ADJ'] + dfx3['ADP'] + dfx3['ADV'] + dfx3['AUX'] + dfx3['CCONJ'] + dfx3['DET'] + dfx3['INTJ'] + dfx3['NOUN'] + dfx3['PART'] + dfx3['PRON'] + dfx3['PROPN'] + dfx3['SCONJ'] + dfx3['VERB']\n",
        "dfx3['sum_sent'] = 0\n",
        "for ind in dfx3.index:\n",
        "  dfx3['sum_sent'][ind] = len(sent_tokenize(open(dfx3['document'][ind]+\".txt\", \"r\").read()))\n",
        "arr = dfx.pos.unique()\n",
        "arr2 = dfx.document.unique()\n",
        "d = {'name': arr2}\n",
        "lst = []\n",
        "dfx2 = pd.DataFrame(data=d)\n",
        "dfx3.insert(0, \"index\", [23,10,11,13,21,24,27,14,17,26,12,15,18,16,0,5,30,19,22,25,20,1,2,6,8,28,31,3,7,29,9,32,4])\n",
        "dfx3.set_index(\"index\", inplace = True)\n",
        "dfx3 = dfx3.sort_values(by=['index'])\n",
        "textlist2 = []\n",
        "textlist2.append(open(\"2 Hupsov šlabikár Lipka pre 1. ročník ZŠ, 1. časť.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"3 Pracovný zošit k Hupsovmu šlabikáru Lipka pre 1. ročník ZŠ.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Prvouka pre 1. ročník ZŠ.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Slovenský jazyk pre 2. ročník ZŠ.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Čítanka pre 2. ročník ZŠ.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Matematika pre 2. ročník ZŠ, 1. časť - pracovný zošit.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Prírodoveda pre 3. ročník ZŠ.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Slovenský jazyk pre 3. ročník ZŠ.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Prírodoveda pre 4. ročník ZŠ - pracovná učebnica.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Slovenský jazyk pre 4. ročník ZŠ.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Biológia pre 5. ročník ZŠ.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Biológia pre 6. ročník ZŠ a 1. ročník gymnázia s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Fyzika pre 6. ročník ZŠ a 1. ročník gymnázií s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Biológia pre 7. ročník ZŠ a 2. ročník gymnázia s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Dejepis pre 8. ročník ZŠ a 3. ročník gymnázia s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Fyzika pre 8. ročník ZŠ a 3. ročník gymnázia s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Geografia pre 8. ročník ZŠ a 3. ročník gymnázia s osemročným štúdiom-pages-2.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Dejepis pre 9. ročník ZŠ a 4. ročník gymnázia s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Fyzika pre 9. ročník ZŠ a 4. ročník gymnázia s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Matematika pre 9. ročník ZŠ a 4. ročník gymnázia s osemročným štúdiom, 1. časť.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Občianska náuka pre 9. ročník ZŠ a 4. ročník gymnázia s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Chémia pre 1. ročník gymnázia so štvorročným štúdiom a 5. ročník gymnázia s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Občianska náuka pre 1. ročník odborných učilíšť (pre žiakov s MP).txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Biológia 6 pre gymnáziá – Vznik života na Zemi a evolúcia, Biológia človeka.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Chémia pre 2. ročník gymnázia so štvorročným štúdiom a 6. ročník gymnázia s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Občianska náuka pre 2. ročník odborných učilíšť (pre žiakov s MP).txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Fyzika pre 3. ročník gymnázia a 7. ročník gymnázia s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Chémia pre 3. ročník gymnázia a 7. ročník gymnázia s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Slovenská literatúra pre 3. ročník stredných škôl a 7. ročník gymnázia s osemročným štúdiom s VJM.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Slovenský jazyk pre 3. ročník stredných škôl a 7. ročník gymnázia s osemročným štúdiom s VJM.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Matematika pre 4. ročník gymnázia a 8. ročník gymnázia s osemročným štúdiom.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Slovenská literatúra pre 4. ročník stredných škôl a 8. ročník gymnázií s osemročným štúdiom s VJM.txt\", \"r\").read().strip())\n",
        "textlist2.append(open(\"2 Slovenský jazyk pre 4. ročník stredných škôl a 8. ročník gymnázií s osemročným štúdiom s VJM.txt\", \"r\").read().strip())\n",
        "vetylist = []\n",
        "syllabelsstart = []\n",
        "syllabelsend = []\n",
        "syllabelsmid = []\n",
        "for i in textlist2:\n",
        "  vetylist.append(sent_tokenize(i))\n",
        "for i in vetylist:\n",
        "  for j in i[:10]:\n",
        "    nltk_tokens = nltk.word_tokenize(j)\n",
        "    syl = 0\n",
        "    for k in nltk_tokens:\n",
        "      if syllab_count(k) >= 3:\n",
        "        syl = syl + 1\n",
        "  syllabelsstart.append(syl)\n",
        "  for j in i[-10:]:\n",
        "    nltk_tokens = nltk.word_tokenize(j)\n",
        "    syl = 0\n",
        "    for k in nltk_tokens:\n",
        "      if syllab_count(k) >= 3:\n",
        "        syl = syl + 1\n",
        "  syllabelsend.append(syl)\n",
        "  for j in i[round(len(i)/2)-5:round(len(i)/2)+5]:\n",
        "    nltk_tokens = nltk.word_tokenize(j)\n",
        "    syl = 0\n",
        "    for k in nltk_tokens:\n",
        "      if syllab_count(k) >= 3:\n",
        "        syl = syl + 1\n",
        "  syllabelsmid.append(syl)\n",
        "dfx3[\"syl_start\"] = syllabelsstart\n",
        "dfx3[\"syl_end\"] = syllabelsend\n",
        "dfx3[\"syl_mid\"] = syllabelsmid"
      ],
      "metadata": {
        "id": "3lxFjKNLpudO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4bPG65q8V94D"
      },
      "outputs": [],
      "source": [
        "vetylist = []\n",
        "gun_sent = []\n",
        "gun_word = []\n",
        "gun_hard_word = []\n",
        "for i in textlist2:\n",
        "  vetylist.append(sent_tokenize(i))\n",
        "for i in vetylist:\n",
        "  pocviet = 0\n",
        "  pocslov = 0\n",
        "  poctazslov = 0\n",
        "  for j in i:\n",
        "    pocviet = pocviet + 1\n",
        "    nltk_tokens = nltk.word_tokenize(j)\n",
        "    for k in nltk_tokens:\n",
        "      if syllab_count(k) > 0:\n",
        "        pocslov = pocslov + 1\n",
        "        k = k.replace(\".\", \"\")\n",
        "        k = k.replace(\"€\", \"\")\n",
        "        sl_druh = \"\"\n",
        "        try:\n",
        "          sl_druh = dfx.loc[dfx['word'] == k][\"pos\"].loc[dfx.loc[dfx['word'] == k].index[0]]\n",
        "          lema = dfx.loc[dfx['word'] == k][\"lemma\"].loc[dfx.loc[dfx['word'] == k].index[0]]\n",
        "          if syllab_count(lema) >= 3 and sl_druh != \"NOUN\":\n",
        "            poctazslov = poctazslov + 1\n",
        "        except:\n",
        "          if syllab_count(k) >= 3 and sl_druh != \"NOUN\":\n",
        "            poctazslov = poctazslov + 1\n",
        "    if pocslov >= 100:\n",
        "      gun_sent.append(pocviet)\n",
        "      gun_word.append(pocslov)\n",
        "      gun_hard_word.append(poctazslov)\n",
        "      pocviet = 0\n",
        "      pocslov = 0\n",
        "      poctazslov = 0\n",
        "      break\n",
        "dfx3[\"gun_sent\"] = gun_sent\n",
        "dfx3[\"gun_word\"] = gun_word\n",
        "dfx3[\"gun_hard_word\"] = gun_hard_word"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "charlist = []\n",
        "for i in textlist2:\n",
        "  charlist.append(len(i))\n",
        "dfx3[\"charlist\"] = charlist\n",
        "vetylist = []\n",
        "lin_syl = []\n",
        "for i in textlist2:\n",
        "  vetylist.append(sent_tokenize(i))\n",
        "for i in vetylist:\n",
        "  wordlist = []\n",
        "  pocslov = 0\n",
        "  for j in i:\n",
        "    pocviet = pocviet + 1\n",
        "    nltk_tokens = nltk.word_tokenize(j)\n",
        "    for k in nltk_tokens:\n",
        "      if syllab_count(k) > 0:\n",
        "        pocslov = pocslov + 1\n",
        "        wordlist.append(k)\n",
        "    if pocslov >= 100:\n",
        "      pocslov = 0\n",
        "      break\n",
        "  wordlist = wordlist[:100]\n",
        "  syl = 0\n",
        "  for l in wordlist:\n",
        "    if syllab_count(l) >= 3:\n",
        "      syl = syl + 3\n",
        "    else:\n",
        "      syl = syl + 1\n",
        "  lin_syl.append(syl)\n",
        "dfx3[\"lin_syl\"] = lin_syl\n",
        "vetylist = []\n",
        "hard_words = []\n",
        "unique_words = []\n",
        "for i in textlist2:\n",
        "  vetylist.append(sent_tokenize(i))\n",
        "for i in vetylist:\n",
        "  pocunikslov = 0\n",
        "  poctazslov = 0\n",
        "  for j in i:\n",
        "    nltk_tokens = nltk.word_tokenize(j)\n",
        "    pocunikslov = pocunikslov + len(Counter(nltk_tokens).keys())\n",
        "    for k in nltk_tokens:\n",
        "      if syllab_count(k) > 0:\n",
        "        if k not in keywords:\n",
        "          poctazslov = poctazslov + 1\n",
        "  hard_words.append(poctazslov)\n",
        "  unique_words.append(pocunikslov)\n",
        "dfx3[\"hard_words\"] = hard_words\n",
        "dfx3[\"unique_words\"] = unique_words\n",
        "dfx3.to_csv('tabx1.csv', sep=';', encoding='utf-16', index=False)\n",
        "dfx.to_csv('text_MR_4.csv', sep=';', encoding='utf-16', index=False)\n",
        "metricslist = []\n",
        "for i in textlist2:\n",
        "  metricslist.append(td.extract_metrics(text=i, lang=\"en\", metrics=['readability']))\n",
        "df2TD = pd.concat(metricslist)\n",
        "df2TD.insert(0, \"name\", [\"metrics1SJ\",\"metrics1SJL\",\"metrics1PR\",\"metrics2SJ\",\"metrics2SJL\",\"metrics2MAT\",\"metrics3PR\",\"metrics3SJ\",\"metrics4PR\",\"metrics4SJ\",\"metrics5PR\",\"metrics6PR\",\"metrics6FYZ\",\"metrics7PR\",\"metrics8DEJ\",\"metrics8FYZ\",\"metrics8GEO\",\"metrics9DEJ\",\"metrics9FYZ\",\"metrics9MAT\",\"metrics9OBN\",\"metrics10CHE\",\"metrics10OBN\",\"metrics11PR\",\"metrics11CHE\",\"metrics11OBN\",\"metrics12FYZ\",\"metrics12CHE\",\"metrics12SJL\",\"metrics12SJ\",\"metrics13MAT\",\"metrics13SJL\",\"metrics13SJ\"])\n",
        "df2TD.insert(1, \"document\", [\"Hupsov šlabikár Lipka pre 1. ročník ZŠ, 1. časť\",\"Pracovný zošit k Hupsovmu šlabikáru Lipka pre 1. ročník ZŠ\",\"Prvouka pre 1. ročník ZŠ\",\"Slovenský jazyk pre 2. ročník ZŠ\",\"Čítanka pre 2. ročník ZŠ\",\"Matematika pre 2. ročník ZŠ, 1. časť - pracovný zošit\",\"Prírodoveda pre 3. ročník ZŠ\",\"Slovenský jazyk pre 3. ročník ZŠ\",\"Prírodoveda pre 4. ročník ZŠ - pracovná učebnica\",\"Slovenský jazyk pre 4. ročník ZŠ\",\"Biológia pre 5. ročník ZŠ\",\"Biológia pre 6. ročník ZŠ a 1. ročník gymnázia s osemročným štúdiom\",\"Fyzika pre 6. ročník ZŠ a 1. ročník gymnázií s osemročným štúdiom\",\"Biológia pre 7. ročník ZŠ a 2. ročník gymnázia s osemročným štúdiom\",\"Dejepis pre 8. ročník ZŠ a 3. ročník gymnázia s osemročným štúdiom\",\"Fyzika pre 8. ročník ZŠ a 3. ročník gymnázia s osemročným štúdiom\",\"Geografia pre 8. ročník ZŠ a 3. ročník gymnázia s osemročným štúdiom-pages-2\",\"Dejepis pre 9. ročník ZŠ a 4. ročník gymnázia s osemročným štúdiom\",\"Fyzika pre 9. ročník ZŠ a 4. ročník gymnázia s osemročným štúdiom\",\"Matematika pre 9. ročník ZŠ a 4. ročník gymnázia s osemročným štúdiom, 1. časť\",\"Občianska náuka pre 9. ročník ZŠ a 4. ročník gymnázia s osemročným štúdiom\",\"Chémia pre 1. ročník gymnázia so štvorročným štúdiom a 5. ročník gymnázia s osemročným štúdiom\",\"Občianska náuka pre 1. ročník odborných učilíšť (pre žiakov s MP)\",\"Biológia 6 pre gymnáziá – Vznik života na Zemi a evolúcia, Biológia človeka\",\"Chémia pre 2. ročník gymnázia so štvorročným štúdiom a 6. ročník gymnázia s osemročným štúdiom\",\"Občianska náuka pre 2. ročník odborných učilíšť (pre žiakov s MP)\",\"Fyzika pre 3. ročník gymnázia a 7. ročník gymnázia s osemročným štúdiom\",\"Chémia pre 3. ročník gymnázia a 7. ročník gymnázia s osemročným štúdiom\",\"Slovenská literatúra pre 3. ročník stredných škôl a 7. ročník gymnázia s osemročným štúdiom s VJM\",\"Slovenský jazyk pre 3. ročník stredných škôl a 7. ročník gymnázia s osemročným štúdiom s VJM\",\"Matematika pre 4. ročník gymnázia a 8. ročník gymnázia s osemročným štúdiom\",\"Slovenská literatúra pre 4. ročník stredných škôl a 8. ročník gymnázií s osemročným štúdiom s VJM\",\"Slovenský jazyk pre 4. ročník stredných škôl a 8. ročník gymnázií s osemročným štúdiom s VJM\"])\n",
        "df2TD.insert(2, \"year\", [1,1,1,2,2,2,3,3,4,4,5,6,6,7,8,8,8,9,9,9,9,10,10,11,11,11,12,12,12,12,13,13,13])\n",
        "df2TD.insert(2, \"grade\", [1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3])\n",
        "df2TD.insert(3, \"subject\", [\"SJ\",\"SJL\",\"PR\",\"SJ\",\"SJL\",\"MAT\",\"PR\",\"SJ\",\"PR\",\"SJ\",\"PR\",\"PR\",\"FYZ\",\"PR\",\"DEJ\",\"FYZ\",\"GEO\",\"DEJ\",\"FYZ\",\"MAT\",\"OBN\",\"CHE\",\"OBN\",\"PR\",\"CHE\",\"OBN\",\"FYZ\",\"CHE\",\"SJL\",\"SJ\",\"MAT\",\"SJL\",\"SJ\"])\n",
        "df2TD.reset_index(inplace = True)\n",
        "df2TD = df2TD.drop([\"index\",\"text\"], axis=1)\n",
        "Readabilitylist = []\n",
        "for i in textlist2:\n",
        "  Readabilitylist.append(Readability(i))\n",
        "fklist = []\n",
        "fklist_score = []\n",
        "fklist_grade_level = []\n",
        "flist = []\n",
        "flist_score = []\n",
        "flist_ease = []\n",
        "flist_grade_level = []\n",
        "dclist = []\n",
        "dclist_score = []\n",
        "dclist_grade_level = []\n",
        "arilist = []\n",
        "arilist_score = []\n",
        "arilist_grade_level = []\n",
        "arilist_ages = []\n",
        "cllist = []\n",
        "cllist_score = []\n",
        "cllist_grade_level = []\n",
        "gflist = []\n",
        "gflist_score = []\n",
        "gflist_grade_level = []\n",
        "smoglist = []\n",
        "smoglist_score = []\n",
        "smoglist_grade_level = []\n",
        "smogalist = []\n",
        "smogalist_score = []\n",
        "smogalist_grade_level = []\n",
        "slist = []\n",
        "slist_score = []\n",
        "slist_grade_level = []\n",
        "lwlist = []\n",
        "lwlist_score = []\n",
        "lwlist_grade_level = []\n",
        "for i in Readabilitylist:\n",
        "  fklist.append(i.flesch_kincaid())\n",
        "  flist.append(i.flesch())\n",
        "  dclist.append(i.dale_chall())\n",
        "  arilist.append(i.ari())\n",
        "  cllist.append(i.coleman_liau())\n",
        "  gflist.append(i.gunning_fog())\n",
        "  smoglist.append(i.smog())\n",
        "  smogalist.append(i.smog(all_sentences=True))\n",
        "  slist.append(i.spache())\n",
        "  lwlist.append(i.linsear_write())\n",
        "for i in fklist:\n",
        "  fklist_score.append(i.score)\n",
        "  fklist_grade_level.append(i.grade_level)\n",
        "df2TD.insert(len(df2TD.columns),\"R_flesch_kincaid_score\", fklist_score, True)\n",
        "df2TD.insert(len(df2TD.columns),\"R_flesch_kincaid_grade_level\", fklist_grade_level, True)\n",
        "for i in flist:\n",
        "  flist_score.append(i.score)\n",
        "  flist_ease.append(i.ease)\n",
        "  flist_grade_level.append(i.grade_levels)\n",
        "df2TD.insert(len(df2TD.columns),\"R_flesch_score\", flist_score, True)\n",
        "df2TD.insert(len(df2TD.columns),\"R_flesch_ease\", flist_ease, True)\n",
        "df2TD.insert(len(df2TD.columns),\"R_flesch_grade_levels\", flist_grade_level, True)\n",
        "for i in dclist:\n",
        "  dclist_score.append(i.score)\n",
        "  dclist_grade_level.append(i.grade_levels)\n",
        "df2TD.insert(len(df2TD.columns),\"R_dale_chall_score\", dclist_score, True)\n",
        "df2TD.insert(len(df2TD.columns),\"R_dale_chall_grade_levels\", dclist_grade_level, True)\n",
        "for i in arilist:\n",
        "  arilist_score.append(i.score)\n",
        "  arilist_ages.append(i.ages)\n",
        "  arilist_grade_level.append(i.grade_levels)\n",
        "df2TD.insert(len(df2TD.columns),\"R_ari_score\", arilist_score, True)\n",
        "df2TD.insert(len(df2TD.columns),\"R_ari_grade_levels\", arilist_grade_level, True)\n",
        "df2TD.insert(len(df2TD.columns),\"R_ari_ages\", arilist_ages, True)\n",
        "for i in cllist:\n",
        "  cllist_score.append(i.score)\n",
        "  cllist_grade_level.append(i.grade_level)\n",
        "df2TD.insert(len(df2TD.columns),\"R_coleman_liau_score\", cllist_score, True)\n",
        "df2TD.insert(len(df2TD.columns),\"R_coleman_liau_grade_level\", cllist_grade_level, True)\n",
        "for i in gflist:\n",
        "  gflist_score.append(i.score)\n",
        "  gflist_grade_level.append(i.grade_level)\n",
        "df2TD.insert(len(df2TD.columns),\"R_gunning_fog_score\", gflist_score, True)\n",
        "df2TD.insert(len(df2TD.columns),\"R_gunning_fog_grade_level\", gflist_grade_level, True)\n",
        "for i in smoglist:\n",
        "  smoglist_score.append(i.score)\n",
        "  smoglist_grade_level.append(i.grade_level)\n",
        "df2TD.insert(len(df2TD.columns),\"R_smog_score\", smoglist_score, True)\n",
        "df2TD.insert(len(df2TD.columns),\"R_smog_grade_level\", smoglist_grade_level, True)\n",
        "for i in smogalist:\n",
        "  smogalist_score.append(i.score)\n",
        "  smogalist_grade_level.append(i.grade_level)\n",
        "df2TD.insert(len(df2TD.columns),\"R_smog_all_sentences_score\", smogalist_score, True)\n",
        "df2TD.insert(len(df2TD.columns),\"R_smog_all_sentences_grade_level\", smogalist_grade_level, True)\n",
        "for i in slist:\n",
        "  slist_score.append(i.score)\n",
        "  slist_grade_level.append(i.grade_level)\n",
        "df2TD.insert(len(df2TD.columns),\"R_spache_score\", slist_score, True)\n",
        "df2TD.insert(len(df2TD.columns),\"R_spache_grade_level\", slist_grade_level, True)\n",
        "for i in lwlist:\n",
        "  lwlist_score.append(i.score)\n",
        "  lwlist_grade_level.append(i.grade_level)\n",
        "df2TD.insert(len(df2TD.columns),\"R_linsear_write_score\", lwlist_score, True)\n",
        "df2TD.insert(len(df2TD.columns),\"R_linsear_write_grade_level\", lwlist_grade_level, True)\n",
        "tfllist = []\n",
        "tfkglist = []\n",
        "tgflist = []\n",
        "tsmoglist = []\n",
        "tarilist = []\n",
        "tcllist = []\n",
        "tdclist = []\n",
        "tstdlist = []\n",
        "tlwlist = []\n",
        "tslist = []\n",
        "teflawlist = []\n",
        "trtlist = []\n",
        "tsyllist = []\n",
        "tlexlist = []\n",
        "tsentlist = []\n",
        "tcharlist = []\n",
        "tletlist = []\n",
        "tpolylist = []\n",
        "tmonolist = []\n",
        "tdifflist = []\n",
        "for i in textlist2:\n",
        "  tfllist.append(textstat.flesch_reading_ease(i))\n",
        "  tfkglist.append(textstat.flesch_kincaid_grade(i))\n",
        "  tgflist.append(textstat.gunning_fog(i))\n",
        "  tsmoglist.append(textstat.smog_index(i))\n",
        "  tarilist.append(textstat.automated_readability_index(i))\n",
        "  tcllist.append(textstat.coleman_liau_index(i))\n",
        "  tlwlist.append(textstat.linsear_write_formula(i))\n",
        "  tdclist.append(textstat.dale_chall_readability_score(i))\n",
        "  tstdlist.append(textstat.text_standard(i, float_output=False))\n",
        "  tslist.append(textstat.spache_readability(i))\n",
        "  teflawlist.append(textstat.mcalpine_eflaw(i))\n",
        "  trtlist.append(textstat.reading_time(i, ms_per_char=14.69))\n",
        "  tsyllist.append(textstat.syllable_count(i))\n",
        "  tlexlist.append(textstat.lexicon_count(i, removepunct=True))\n",
        "  tsentlist.append(textstat.sentence_count(i))\n",
        "  tcharlist.append(textstat.char_count(i, ignore_spaces=True))\n",
        "  tletlist.append(textstat.letter_count(i, ignore_spaces=True))\n",
        "  tpolylist.append(textstat.polysyllabcount(i))\n",
        "  tmonolist.append(textstat.monosyllabcount(i))\n",
        "  tdifflist.append(textstat.difficult_words(i))\n",
        "df2TD.insert(len(df2TD.columns),\"T_flesch_reading_ease\", tfllist, True)\n",
        "df2TD.insert(len(df2TD.columns),\"T_flesch_kincaid_grade\", tfkglist, True)\n",
        "df2TD.insert(len(df2TD.columns),\"T_gunning_fog\", tgflist, True)\n",
        "df2TD.insert(len(df2TD.columns),\"T_smog_index\", tsmoglist, True)\n",
        "df2TD.insert(len(df2TD.columns),\"T_automated_readability_index\", tarilist, True)\n",
        "df2TD.insert(len(df2TD.columns),\"T_coleman_liau_index\", tcllist, True)\n",
        "df2TD.insert(len(df2TD.columns),\"T_linsear_write_formula\", tlwlist, True)\n",
        "df2TD.insert(len(df2TD.columns),\"T_dale_chall_readability_score\", tdclist, True)\n",
        "df2TD.insert(len(df2TD.columns),\"T_text_standard\", tstdlist, True)\n",
        "df2TD.insert(len(df2TD.columns),\"T_spache_readability\", tslist, True)\n",
        "df2TD.insert(len(df2TD.columns),\"T_mcalpine_eflaw\", teflawlist, True)\n",
        "df2TD.insert(len(df2TD.columns),\"T_reading_time\", trtlist, True)\n",
        "df2TD.insert(len(df2TD.columns),\"T_syllable_count\", tsyllist, True)\n",
        "df2TD.insert(len(df2TD.columns),\"T_lexicon_count\", tlexlist, True)\n",
        "df2TD.insert(len(df2TD.columns),\"T_sentence_count\", tsentlist, True)\n",
        "df2TD.insert(len(df2TD.columns),\"T_char_count\", tcharlist, True)\n",
        "df2TD.insert(len(df2TD.columns),\"T_letter_count\", tletlist, True)\n",
        "df2TD.insert(len(df2TD.columns),\"T_polysyllabcount\", tpolylist, True)\n",
        "df2TD.insert(len(df2TD.columns),\"T_monosyllabcount\", tmonolist, True)\n",
        "df2TD.insert(len(df2TD.columns),\"T_difficult_words\", tdifflist, True)\n",
        "df2TD.to_csv('tabx2.csv', sep=';', encoding='utf-16', index=False)"
      ],
      "metadata": {
        "id": "0pCoAgg9sFAO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Výpočet našich vzorcov po odstránení úvodov a záverov z pôvodných textov:"
      ],
      "metadata": {
        "id": "EzKccSIOxstg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "W_lQAZ-qUoVX"
      },
      "outputs": [],
      "source": [
        "df2comp = df2TD[['name', \"document\", 'year', 'grade', 'subject', 'token_length_mean', 'token_length_median', 'token_length_std', 'sentence_length_mean', 'sentence_length_median', 'sentence_length_std', 'syllables_per_token_mean', 'syllables_per_token_median', 'syllables_per_token_std', 'n_tokens', 'T_lexicon_count', 'n_unique_tokens', 'proportion_unique_tokens', 'n_characters', 'T_char_count', 'T_letter_count', 'n_sentences', 'T_sentence_count', 'T_reading_time', 'T_syllable_count', 'T_polysyllabcount', 'T_monosyllabcount', 'T_difficult_words']]\n",
        "df2comp.insert(15, \"sum_words\", dfx3[\"sum_words\"])\n",
        "df2comp.insert(16, \"sum_words_2\", dfx3[\"sum_words_2\"])\n",
        "df2comp.insert(22, \"charlist\", dfx3[\"charlist\"])\n",
        "df2comp.insert(23, \"sum_sent\", dfx3[\"sum_sent\"])\n",
        "df2comp.insert(27, \"syllables\", dfx3[\"syllables\"])\n",
        "df2comp.insert(29, \"multi syllables\", dfx3[2] + dfx3[3] + dfx3[4] + dfx3[\"many\"])\n",
        "df2comp.insert(30, \"two syllables\", dfx3[2])\n",
        "df2comp.insert(31, \"three syllables\", dfx3[3])\n",
        "df2comp.insert(32, \"four syllables\", dfx3[4])\n",
        "df2comp.insert(34, \"many syllables\", dfx3[\"many\"])\n",
        "df2comp.insert(36, \"single syllables\", dfx3[1])\n",
        "df2comp.insert(38, \"smog_syllables\", dfx3[\"syl_start\"]+dfx3[\"syl_end\"]+dfx3[\"syl_mid\"])\n",
        "df2comp.insert(40, \"gun_sent\", dfx3[\"gun_sent\"])\n",
        "df2comp.insert(41, \"gun_word\", dfx3[\"gun_word\"])\n",
        "df2comp.insert(42, \"gun_hard_word\", dfx3[\"gun_hard_word\"])\n",
        "df2comp.insert(43, \"lin_syl\", dfx3[\"lin_syl\"])\n",
        "df2comp.insert(44, \"hard_words\", dfx3[\"hard_words\"])\n",
        "df2comp.insert(45, \"unique_words\", dfx3[\"unique_words\"])\n",
        "df2comp.insert(46, \"NUM\", dfx3[\"NUM\"])\n",
        "df2comp.insert(47, \"PROPN\", dfx3[\"PROPN\"])\n",
        "df2comp.insert(48, \"SCONJ\", dfx3[\"SCONJ\"])\n",
        "df2metr = df2TD[['name', \"document\", 'year', 'grade', 'subject', 'flesch_kincaid_grade', 'R_flesch_kincaid_grade_level', 'T_flesch_kincaid_grade', 'smog', 'R_smog_score', 'R_smog_all_sentences_score', 'T_smog_index', 'gunning_fog', 'R_gunning_fog_score', 'T_gunning_fog', 'automated_readability_index', 'R_ari_score', 'T_automated_readability_index', 'coleman_liau_index', 'R_coleman_liau_score', 'T_coleman_liau_index', 'R_spache_score', 'T_spache_readability', 'R_linsear_write_score', 'T_linsear_write_formula', 'R_dale_chall_score', 'T_dale_chall_readability_score']]\n",
        "df2metr.insert(8, \"M_flesch_kincaid\", 0)\n",
        "df2metr.insert(13, \"M_smog\", 0)\n",
        "df2metr.insert(17, \"M_gunning_fog\", 0)\n",
        "df2metr.insert(21, \"M_ari\", 0)\n",
        "df2metr.insert(25, \"M_coleman_liau\", 0)\n",
        "df2metr.insert(28, \"M_spache\", 0)\n",
        "df2metr.insert(31, \"M_linsear_write\", 0)\n",
        "df2metr.insert(34, \"M_dale_chall\", 0)\n",
        "df2metr.insert(35, \"M_Mistrík\", 0)\n",
        "for ind in df2metr.index:\n",
        "  df2metr['M_flesch_kincaid'][ind] = 0.39*(df2comp[\"sum_words\"][ind]/df2comp[\"sum_sent\"][ind])+11.8*(df2comp[\"syllables\"][ind]/df2comp[\"sum_words\"][ind])-15.59\n",
        "  df2metr['M_smog'][ind] = 3 + math.sqrt(df2comp['smog_syllables'][ind])\n",
        "  df2metr['M_gunning_fog'][ind] = 0.4*(df2comp['gun_word'][ind]/df2comp['gun_sent'][ind] + 100*(df2comp['gun_hard_word'][ind]/df2comp['gun_word'][ind]))\n",
        "  df2metr['M_ari'][ind] = 0.5*(df2comp['sum_words'][ind]/df2comp['sum_sent'][ind]) + 4.71*(df2comp['charlist'][ind]/df2comp['sum_words'][ind])-21.43\n",
        "  df2metr['M_coleman_liau'][ind] = 5.88*(df2comp['charlist'][ind]/df2comp['sum_words'][ind])-29.6*(df2comp['sum_sent'][ind]/df2comp['sum_words'][ind])-15.8\n",
        "  df2metr['M_spache'][ind] = (0.121*df2comp['sum_words'][ind]/df2comp['sum_sent'][ind])+(8.2*df2comp['hard_words'][ind]/df2comp['sum_words'][ind])+0.659\n",
        "  if (df2comp['lin_syl'][ind]/df2comp['gun_sent'][ind]) > 20:\n",
        "    df2metr['M_linsear_write'][ind] = (df2comp['lin_syl'][ind]/df2comp['gun_sent'][ind])/2\n",
        "  else:\n",
        "    df2metr['M_linsear_write'][ind] = (df2comp['lin_syl'][ind]/df2comp['gun_sent'][ind])/2-1\n",
        "  df2metr['M_dale_chall'][ind] = 0.1579*(df2comp['hard_words'][ind]/df2comp['sum_words'][ind]*100) + 0.0496*(df2comp['sum_words'][ind]/df2comp['sum_sent'][ind])\n",
        "  df2metr['M_Mistrík'][ind] = 50-(((df2comp['sum_words'][ind]/df2comp['sum_sent'][ind])*(df2comp[\"syllables\"][ind]/df2comp[\"sum_words\"][ind]))/(df2comp[\"sum_words\"][ind]/df2comp[\"unique_words\"][ind]))\n",
        "df2metrx = df2TD[['name', \"document\", 'year', 'grade', 'subject']]\n",
        "df2metrx.insert(5, \"M_flesch_kincaid\", 0)\n",
        "df2metrx.insert(6, \"M_smog\", 0)\n",
        "df2metrx.insert(7, \"M_gunning_fog\", 0)\n",
        "df2metrx.insert(8, \"M_ari\", 0)\n",
        "df2metrx.insert(9, \"M_coleman_liau\", 0)\n",
        "df2metrx.insert(10, \"M_spache\", 0)\n",
        "df2metrx.insert(11, \"M_linsear_write\", 0)\n",
        "df2metrx.insert(12, \"M_dale_chall\", 0)\n",
        "df2metrx.insert(13, \"M_Mistrík\", 0)\n",
        "for ind in df2metrx.index:\n",
        "  df2metrx['M_flesch_kincaid'][ind] = 0.39*(df2comp[\"sum_words_2\"][ind]/df2comp[\"sum_sent\"][ind])+11.8*(df2comp[\"syllables\"][ind]/df2comp[\"sum_words_2\"][ind])-15.59\n",
        "  df2metrx['M_smog'][ind] = 3 + math.sqrt(df2comp['smog_syllables'][ind])\n",
        "  df2metrx['M_gunning_fog'][ind] = 0.4*(df2comp['gun_word'][ind]/df2comp['gun_sent'][ind] + 100*(df2comp['gun_hard_word'][ind]/df2comp['gun_word'][ind]))\n",
        "  df2metrx['M_ari'][ind] = 0.5*(df2comp['sum_words_2'][ind]/df2comp['sum_sent'][ind]) + 4.71*(df2comp['charlist'][ind]/df2comp['sum_words_2'][ind])-21.43\n",
        "  df2metrx['M_coleman_liau'][ind] = 5.88*(df2comp['charlist'][ind]/df2comp['sum_words_2'][ind])-29.6*(df2comp['sum_sent'][ind]/df2comp['sum_words_2'][ind])-15.8\n",
        "  df2metrx['M_spache'][ind] = (0.121*df2comp['sum_words_2'][ind]/df2comp['sum_sent'][ind])+(8.2*df2comp['hard_words'][ind]/df2comp['sum_words_2'][ind])+0.659\n",
        "  if (df2comp['lin_syl'][ind]/df2comp['gun_sent'][ind]) > 20:\n",
        "    df2metrx['M_linsear_write'][ind] = (df2comp['lin_syl'][ind]/df2comp['gun_sent'][ind])/2\n",
        "  else:\n",
        "    df2metrx['M_linsear_write'][ind] = (df2comp['lin_syl'][ind]/df2comp['gun_sent'][ind])/2-1\n",
        "  df2metrx['M_dale_chall'][ind] = 0.1579*(df2comp['hard_words'][ind]/df2comp['sum_words_2'][ind]*100) + 0.0496*(df2comp['sum_words_2'][ind]/df2comp['sum_sent'][ind])\n",
        "  df2metrx['M_Mistrík'][ind] = 50-(((df2comp['sum_words_2'][ind]/df2comp['sum_sent'][ind])*(df2comp[\"syllables\"][ind]/df2comp[\"sum_words_2\"][ind]))/(df2comp[\"sum_words_2\"][ind]/df2comp[\"unique_words\"][ind]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metriky ARI a Coleman-Liau vypočítame ešte raz, ale tentokrát počítame slová podľa pôvodných pravidiel:"
      ],
      "metadata": {
        "id": "hAxHZ_b1x3hu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2metry = df2TD[['name', \"document\", 'year', 'grade', 'subject']]\n",
        "df2metry.insert(5, \"M_ari\", 0)\n",
        "df2metry.insert(6, \"M_coleman_liau\", 0)\n",
        "\n",
        "for ind in df2metry.index:\n",
        "  df2metry['M_ari'][ind] = 0.5*(df2comp['sum_words'][ind]/df2comp['sum_sent'][ind]) + 4.71*(df2comp['charlist'][ind]/df2comp['sum_words'][ind])-21.43\n",
        "  df2metry['M_coleman_liau'][ind] = 5.88*(df2comp['charlist'][ind]/df2comp['sum_words'][ind])-29.6*(df2comp['sum_sent'][ind]/df2comp['sum_words'][ind])-15.8\n",
        "df2metry.to_csv('taby45.csv', sep=';', encoding='utf-16', index=False)"
      ],
      "metadata": {
        "id": "KlA16K3lLnA0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pomery hodnôt charakteristík textov:\n",
        "### celkové"
      ],
      "metadata": {
        "id": "hoTh9sJ7yQaP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "VF5H4bH5X-QH"
      },
      "outputs": [],
      "source": [
        "df2comp2 = df2comp[['name', \"document\", 'year', 'grade', 'subject']]\n",
        "df2comp2.insert(5, \"words_per_sent\", 0)\n",
        "df2comp2.insert(6, \"syllabs_per_word\", 0)\n",
        "df2comp2.insert(7, \"letters_per_word\", 0)\n",
        "df2comp2.insert(8, \"longwords_per_word\", 0)\n",
        "df2comp2.insert(9, \"hardwords_per_word\", 0)\n",
        "df2comp2.insert(10, \"uniquewords_per_word\", 0)\n",
        "for ind in df2metr.index:\n",
        "  df2comp2['words_per_sent'][ind] = df2comp[\"sum_words_2\"][ind]/df2comp[\"sum_sent\"][ind]\n",
        "  df2comp2['syllabs_per_word'][ind] = df2comp[\"syllables\"][ind]/df2comp[\"sum_words_2\"][ind]\n",
        "  df2comp2['letters_per_word'][ind] = df2comp[\"charlist\"][ind]/df2comp[\"sum_words\"][ind]\n",
        "  df2comp2['longwords_per_word'][ind] = dfx3[\"many\"][ind]/df2comp[\"sum_words_2\"][ind]\n",
        "  df2comp2['hardwords_per_word'][ind] = df2comp['hard_words'][ind]/df2comp[\"sum_words_2\"][ind]\n",
        "  df2comp2['uniquewords_per_word'][ind] = df2comp[\"sum_words_2\"][ind]/df2comp[\"unique_words\"][ind]\n",
        "df2metr.to_csv('tabx3.csv', sep=';', encoding='utf-16', index=False)\n",
        "df2comp.to_csv('tabx4.csv', sep=';', encoding='utf-16', index=False)\n",
        "df2metr2 = df2metr[['name', \"document\", 'year', 'grade', 'subject', 'M_flesch_kincaid', 'M_smog', 'M_gunning_fog', 'M_ari', 'M_coleman_liau', 'M_spache', 'M_linsear_write', 'M_dale_chall', 'M_Mistrík']]\n",
        "df2metr2.to_csv('tabx5.csv', sep=';', encoding='utf-16', index=False)\n",
        "df2comp2.to_csv('tabx6.csv', sep=';', encoding='utf-16', index=False)\n",
        "df2metrx.to_csv('tabx45.csv', sep=';', encoding='utf-16', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pomery hodnôt charakteristík textov\n",
        "### (minimá, priemery, maximá), v rámci stupňov štúdia a predmetov a len v rámci stupňov štúdia:"
      ],
      "metadata": {
        "id": "ROQx82bUywzf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "3z-JF3PIYlbf"
      },
      "outputs": [],
      "source": [
        "df2comp3 =df2comp2.groupby(['grade','subject'])[['words_per_sent', 'syllabs_per_word', 'letters_per_word', 'longwords_per_word', 'hardwords_per_word', 'uniquewords_per_word']].mean()\n",
        "df2comp4 =df2comp2.groupby(['grade','subject'])[['words_per_sent', 'syllabs_per_word', 'letters_per_word', 'longwords_per_word', 'hardwords_per_word', 'uniquewords_per_word']].min()\n",
        "df2comp5 =df2comp2.groupby(['grade','subject'])[['words_per_sent', 'syllabs_per_word', 'letters_per_word', 'longwords_per_word', 'hardwords_per_word', 'uniquewords_per_word']].max()\n",
        "for column in df2comp3:\n",
        "  df2comp3 = df2comp3.rename(columns={column: column+\"_aver\"})\n",
        "i = 0\n",
        "for column in df2comp4:\n",
        "  df2comp3.insert(i, column+\"_min\", df2comp4[column])\n",
        "  i = i + 2\n",
        "i = 2\n",
        "for column in df2comp5:\n",
        "  df2comp3.insert(i, column+\"_max\", df2comp5[column])\n",
        "  i = i + 3\n",
        "df2comp3 = df2comp3.reset_index()\n",
        "df2comp6 =df2comp2.groupby(['grade'])[['words_per_sent', 'syllabs_per_word', 'letters_per_word', 'longwords_per_word', 'hardwords_per_word', 'uniquewords_per_word']].mean()\n",
        "df2comp7 =df2comp2.groupby(['grade'])[['words_per_sent', 'syllabs_per_word', 'letters_per_word', 'longwords_per_word', 'hardwords_per_word', 'uniquewords_per_word']].min()\n",
        "df2comp8 =df2comp2.groupby(['grade'])[['words_per_sent', 'syllabs_per_word', 'letters_per_word', 'longwords_per_word', 'hardwords_per_word', 'uniquewords_per_word']].max()\n",
        "for column in df2comp6:\n",
        "  df2comp6 = df2comp6.rename(columns={column: column+\"_aver\"})\n",
        "i = 0\n",
        "for column in df2comp7:\n",
        "  df2comp6.insert(i, column+\"_min\", df2comp7[column])\n",
        "  i = i + 2\n",
        "i = 2\n",
        "for column in df2comp8:\n",
        "  df2comp6.insert(i, column+\"_max\", df2comp8[column])\n",
        "  i = i + 3\n",
        "df2comp6 = df2comp6.reset_index()\n",
        "df2comp3.to_csv('tabx7.csv', sep=';', encoding='utf-16', index=False)\n",
        "df2comp6.to_csv('tabx8.csv', sep=';', encoding='utf-16', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rozhodovací strom:"
      ],
      "metadata": {
        "id": "Gm1uuiICycA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2train = ['words_per_sent', 'syllabs_per_word', 'letters_per_word', 'longwords_per_word', 'hardwords_per_word', 'uniquewords_per_word']\n",
        "X = df2comp2[df2train]\n",
        "y = df2comp2['grade']\n",
        "y=y.astype('int')\n",
        "i = 0\n",
        "while i < 1:\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "  clf = DecisionTreeClassifier(max_depth=5)\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  i = metrics.accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
        "dot_data = tree.export_graphviz(clf, out_file=None, feature_names = df2train,class_names=['1','2','3'], filled=True)\n",
        "graph = graphviz.Source(dot_data, format=\"png\")\n",
        "graph.render('decision tree')\n",
        "graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 934
        },
        "id": "yJTM_Lj_lAR0",
        "outputId": "42c4f257-2417-467e-822f-ce49854c3f99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"774pt\" height=\"671pt\"\n viewBox=\"0.00 0.00 774.00 671.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 667)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-667 770,-667 770,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"#f0e8fc\" stroke=\"black\" points=\"414,-663 214,-663 214,-580 414,-580 414,-663\"/>\n<text text-anchor=\"middle\" x=\"314\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">longwords_per_word &lt;= 0.044</text>\n<text text-anchor=\"middle\" x=\"314\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.648</text>\n<text text-anchor=\"middle\" x=\"314\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 26</text>\n<text text-anchor=\"middle\" x=\"314\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 9, 11]</text>\n<text text-anchor=\"middle\" x=\"314\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 3</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"#fbede3\" stroke=\"black\" points=\"303,-544 133,-544 133,-461 303,-461 303,-544\"/>\n<text text-anchor=\"middle\" x=\"218\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">words_per_sent &lt;= 7.613</text>\n<text text-anchor=\"middle\" x=\"218\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.569</text>\n<text text-anchor=\"middle\" x=\"218\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12</text>\n<text text-anchor=\"middle\" x=\"218\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 5, 1]</text>\n<text text-anchor=\"middle\" x=\"218\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M280.69,-579.91C273.25,-570.83 265.28,-561.12 257.61,-551.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"260.3,-549.53 251.25,-544.02 254.89,-553.97 260.3,-549.53\"/>\n<text text-anchor=\"middle\" x=\"248.79\" y=\"-565.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<polygon fill=\"#b388ef\" stroke=\"black\" points=\"500.5,-544 321.5,-544 321.5,-461 500.5,-461 500.5,-544\"/>\n<text text-anchor=\"middle\" x=\"411\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">syllabs_per_word &lt;= 2.317</text>\n<text text-anchor=\"middle\" x=\"411\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.408</text>\n<text text-anchor=\"middle\" x=\"411\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 14</text>\n<text text-anchor=\"middle\" x=\"411\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4, 10]</text>\n<text text-anchor=\"middle\" x=\"411\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 3</text>\n</g>\n<!-- 0&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>0&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M347.65,-579.91C355.18,-570.83 363.23,-561.12 370.98,-551.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"373.72,-553.95 377.41,-544.02 368.33,-549.49 373.72,-553.95\"/>\n<text text-anchor=\"middle\" x=\"379.73\" y=\"-565.21\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"110,-417.5 0,-417.5 0,-349.5 110,-349.5 110,-417.5\"/>\n<text text-anchor=\"middle\" x=\"55\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"55\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"middle\" x=\"55\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 0, 0]</text>\n<text text-anchor=\"middle\" x=\"55\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M161.45,-460.91C144.69,-448.88 126.38,-435.73 109.74,-423.79\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"111.37,-420.65 101.21,-417.67 107.29,-426.34 111.37,-420.65\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"#9cf2c0\" stroke=\"black\" points=\"328,-425 128,-425 128,-342 328,-342 328,-425\"/>\n<text text-anchor=\"middle\" x=\"228\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">longwords_per_word &lt;= 0.026</text>\n<text text-anchor=\"middle\" x=\"228\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.531</text>\n<text text-anchor=\"middle\" x=\"228\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"middle\" x=\"228\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 5, 1]</text>\n<text text-anchor=\"middle\" x=\"228\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 2</text>\n</g>\n<!-- 1&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>1&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M221.47,-460.91C222.18,-452.56 222.94,-443.67 223.68,-435.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"227.17,-435.28 224.54,-425.02 220.2,-434.69 227.17,-435.28\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"140,-298.5 30,-298.5 30,-230.5 140,-230.5 140,-298.5\"/>\n<text text-anchor=\"middle\" x=\"85\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"85\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"85\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0, 0]</text>\n<text text-anchor=\"middle\" x=\"85\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M178.39,-341.91C163.82,-329.99 147.91,-316.98 133.42,-305.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"135.49,-302.29 125.54,-298.67 131.06,-307.71 135.49,-302.29\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"#61ea9a\" stroke=\"black\" points=\"336,-306 158,-306 158,-223 336,-223 336,-306\"/>\n<text text-anchor=\"middle\" x=\"247\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">words_per_sent &lt;= 10.258</text>\n<text text-anchor=\"middle\" x=\"247\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.278</text>\n<text text-anchor=\"middle\" x=\"247\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"middle\" x=\"247\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 5, 1]</text>\n<text text-anchor=\"middle\" x=\"247\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 2</text>\n</g>\n<!-- 3&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>3&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M234.59,-341.91C235.95,-333.56 237.39,-324.67 238.8,-316.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"242.27,-316.45 240.42,-306.02 235.36,-315.33 242.27,-316.45\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"#39e581\" stroke=\"black\" points=\"166,-179.5 56,-179.5 56,-111.5 166,-111.5 166,-179.5\"/>\n<text text-anchor=\"middle\" x=\"111\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"111\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"middle\" x=\"111\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4, 0]</text>\n<text text-anchor=\"middle\" x=\"111\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 2</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M199.82,-222.91C186.09,-211.1 171.11,-198.22 157.44,-186.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"159.42,-183.54 149.55,-179.67 154.85,-188.84 159.42,-183.54\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"#ffffff\" stroke=\"black\" points=\"385.5,-187 184.5,-187 184.5,-104 385.5,-104 385.5,-187\"/>\n<text text-anchor=\"middle\" x=\"285\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">hardwords_per_word &lt;= 0.617</text>\n<text text-anchor=\"middle\" x=\"285\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"middle\" x=\"285\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"middle\" x=\"285\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 1]</text>\n<text text-anchor=\"middle\" x=\"285\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 2</text>\n</g>\n<!-- 5&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M260.18,-222.91C262.93,-214.47 265.84,-205.48 268.68,-196.74\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"272.08,-197.61 271.84,-187.02 265.42,-195.45 272.08,-197.61\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"#8139e5\" stroke=\"black\" points=\"276,-68 166,-68 166,0 276,0 276,-68\"/>\n<text text-anchor=\"middle\" x=\"221\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"221\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"221\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 1]</text>\n<text text-anchor=\"middle\" x=\"221\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 3</text>\n</g>\n<!-- 7&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>7&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M261.17,-103.73C256.1,-95.06 250.75,-85.9 245.65,-77.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"248.53,-75.17 240.46,-68.3 242.49,-78.7 248.53,-75.17\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"#39e581\" stroke=\"black\" points=\"404,-68 294,-68 294,0 404,0 404,-68\"/>\n<text text-anchor=\"middle\" x=\"349\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"349\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"349\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 0]</text>\n<text text-anchor=\"middle\" x=\"349\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 2</text>\n</g>\n<!-- 7&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>7&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M308.83,-103.73C313.9,-95.06 319.25,-85.9 324.35,-77.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"327.51,-78.7 329.54,-68.3 321.47,-75.17 327.51,-78.7\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<polygon fill=\"#8139e5\" stroke=\"black\" points=\"461,-417.5 351,-417.5 351,-349.5 461,-349.5 461,-417.5\"/>\n<text text-anchor=\"middle\" x=\"406\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"406\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"middle\" x=\"406\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 6]</text>\n<text text-anchor=\"middle\" x=\"406\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 3</text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M409.27,-460.91C408.81,-450.2 408.31,-438.62 407.85,-427.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"411.34,-427.51 407.42,-417.67 404.35,-427.81 411.34,-427.51\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<polygon fill=\"#ffffff\" stroke=\"black\" points=\"658.5,-425 479.5,-425 479.5,-342 658.5,-342 658.5,-425\"/>\n<text text-anchor=\"middle\" x=\"569\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">syllabs_per_word &lt;= 2.425</text>\n<text text-anchor=\"middle\" x=\"569\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"middle\" x=\"569\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"middle\" x=\"569\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4, 4]</text>\n<text text-anchor=\"middle\" x=\"569\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 2</text>\n</g>\n<!-- 10&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>10&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M465.82,-460.91C478.81,-451.29 492.76,-440.95 506.08,-431.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"508.33,-433.78 514.28,-425.02 504.16,-428.16 508.33,-433.78\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<polygon fill=\"#6aeca0\" stroke=\"black\" points=\"637.5,-306 462.5,-306 462.5,-223 637.5,-223 637.5,-306\"/>\n<text text-anchor=\"middle\" x=\"550\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">letters_per_word &lt;= 7.131</text>\n<text text-anchor=\"middle\" x=\"550\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"middle\" x=\"550\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"middle\" x=\"550\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4, 1]</text>\n<text text-anchor=\"middle\" x=\"550\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 2</text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M562.41,-341.91C561.05,-333.56 559.61,-324.67 558.2,-316.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"561.64,-315.33 556.58,-306.02 554.73,-316.45 561.64,-315.33\"/>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\">\n<title>16</title>\n<polygon fill=\"#8139e5\" stroke=\"black\" points=\"766,-298.5 656,-298.5 656,-230.5 766,-230.5 766,-298.5\"/>\n<text text-anchor=\"middle\" x=\"711\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"711\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"711\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 3]</text>\n<text text-anchor=\"middle\" x=\"711\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 3</text>\n</g>\n<!-- 12&#45;&gt;16 -->\n<g id=\"edge16\" class=\"edge\">\n<title>12&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"black\" d=\"M618.27,-341.91C632.73,-329.99 648.53,-316.98 662.91,-305.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"665.25,-307.73 670.75,-298.67 660.8,-302.32 665.25,-307.73\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<polygon fill=\"#39e581\" stroke=\"black\" points=\"541,-179.5 431,-179.5 431,-111.5 541,-111.5 541,-179.5\"/>\n<text text-anchor=\"middle\" x=\"486\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"486\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"middle\" x=\"486\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4, 0]</text>\n<text text-anchor=\"middle\" x=\"486\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 2</text>\n</g>\n<!-- 13&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>13&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M527.8,-222.91C521.76,-211.87 515.21,-199.9 509.12,-188.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"512.01,-186.76 504.14,-179.67 505.87,-190.12 512.01,-186.76\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<polygon fill=\"#8139e5\" stroke=\"black\" points=\"669,-179.5 559,-179.5 559,-111.5 669,-111.5 669,-179.5\"/>\n<text text-anchor=\"middle\" x=\"614\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"614\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"614\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 1]</text>\n<text text-anchor=\"middle\" x=\"614\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 3</text>\n</g>\n<!-- 13&#45;&gt;15 -->\n<g id=\"edge15\" class=\"edge\">\n<title>13&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"black\" d=\"M572.2,-222.91C578.24,-211.87 584.79,-199.9 590.88,-188.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"594.13,-190.12 595.86,-179.67 587.99,-186.76 594.13,-190.12\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x7986dc120b50>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generovanie systémových požiadaviek pre spustenie jupyter notebooku:"
      ],
      "metadata": {
        "id": "65CkljAyyhuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "mtRr13Dt_j7a"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "629b93ee4fd54b7c88a1c5a096ca058a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be6b9d6cf85744848068d2de2e228252",
              "IPY_MODEL_e79edc15169f439dad1461963893d9e6",
              "IPY_MODEL_c82d0035720c4fa5931a91fe8859c250"
            ],
            "layout": "IPY_MODEL_b1fb7e9daf5f4e5d8744c4c5780a65f0"
          }
        },
        "be6b9d6cf85744848068d2de2e228252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e357b03f5e1844c3a48f6741ea7a013c",
            "placeholder": "​",
            "style": "IPY_MODEL_2cc22a36040345d2a714fd3bb4899d0b",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: "
          }
        },
        "e79edc15169f439dad1461963893d9e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe07d95b5ae744e19e78a003c5a2a776",
            "max": 47208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10bab2d7e3b14aa0aab5e00faff4e66f",
            "value": 47208
          }
        },
        "c82d0035720c4fa5931a91fe8859c250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64bf98aa73b14b60933dd7d7e6d9806c",
            "placeholder": "​",
            "style": "IPY_MODEL_8df89b2fd2724f619a2508296bce35bf",
            "value": " 379k/? [00:00&lt;00:00, 10.0MB/s]"
          }
        },
        "b1fb7e9daf5f4e5d8744c4c5780a65f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e357b03f5e1844c3a48f6741ea7a013c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cc22a36040345d2a714fd3bb4899d0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe07d95b5ae744e19e78a003c5a2a776": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10bab2d7e3b14aa0aab5e00faff4e66f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64bf98aa73b14b60933dd7d7e6d9806c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8df89b2fd2724f619a2508296bce35bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70240e545d3f419cb3aa317c399057cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ec36093f0a145e0b1c2f969f3e082e8",
              "IPY_MODEL_67a4e570553d46139e1b07ce74a2a7fd",
              "IPY_MODEL_f3baf206428b495fbd377595003ea9cf"
            ],
            "layout": "IPY_MODEL_242badbc4089499eb0cb01b85645bb4d"
          }
        },
        "4ec36093f0a145e0b1c2f969f3e082e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ffae1082bb9402787a624ca73342a02",
            "placeholder": "​",
            "style": "IPY_MODEL_4b95911a7ded4e62b3fa20212175befe",
            "value": "Downloading https://huggingface.co/stanfordnlp/stanza-sk/resolve/v1.8.0/models/tokenize/snk.pt: 100%"
          }
        },
        "67a4e570553d46139e1b07ce74a2a7fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a3c914f047747c8a25a28a5cbf42656",
            "max": 636681,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f045f5a6e8c49afb23d58d3a82f2d28",
            "value": 636681
          }
        },
        "f3baf206428b495fbd377595003ea9cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef347bacb56d4a94a1be66ef65677f7c",
            "placeholder": "​",
            "style": "IPY_MODEL_82ce8ed476c140739dbcdeac8cc30b82",
            "value": " 637k/637k [00:00&lt;00:00, 19.8MB/s]"
          }
        },
        "242badbc4089499eb0cb01b85645bb4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ffae1082bb9402787a624ca73342a02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b95911a7ded4e62b3fa20212175befe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a3c914f047747c8a25a28a5cbf42656": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f045f5a6e8c49afb23d58d3a82f2d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef347bacb56d4a94a1be66ef65677f7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82ce8ed476c140739dbcdeac8cc30b82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48b47c0b044d4d1f8caf6e954203b903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_586664558c84416a9c4a29a484161ba7",
              "IPY_MODEL_24292664d0174fb287b98898222c68eb",
              "IPY_MODEL_699b2d71f8e8484b8438770a1f75719e"
            ],
            "layout": "IPY_MODEL_c726c373b3ae480d8f1785702934b79a"
          }
        },
        "586664558c84416a9c4a29a484161ba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_880673d6af50434da5bc3474f6d92f1b",
            "placeholder": "​",
            "style": "IPY_MODEL_9a3f40c87a5742f7b3dfb6558a537a38",
            "value": "Downloading https://huggingface.co/stanfordnlp/stanza-sk/resolve/v1.8.0/models/mwt/snk.pt: 100%"
          }
        },
        "24292664d0174fb287b98898222c68eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89df0705e56445dcbd718a6e375dad6d",
            "max": 1749,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_301b833bae6e4e64993292e25c797dc7",
            "value": 1749
          }
        },
        "699b2d71f8e8484b8438770a1f75719e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55b4d7c56f5b46cb9032b53a765e837e",
            "placeholder": "​",
            "style": "IPY_MODEL_dc05f20ad15f451fa8fecef30fd4c7ca",
            "value": " 1.75k/1.75k [00:00&lt;00:00, 70.4kB/s]"
          }
        },
        "c726c373b3ae480d8f1785702934b79a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "880673d6af50434da5bc3474f6d92f1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a3f40c87a5742f7b3dfb6558a537a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89df0705e56445dcbd718a6e375dad6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "301b833bae6e4e64993292e25c797dc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55b4d7c56f5b46cb9032b53a765e837e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc05f20ad15f451fa8fecef30fd4c7ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}